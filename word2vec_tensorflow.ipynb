{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "word2vec_tensorflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftk1000/w2v_ftk1000/blob/master/word2vec_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMrqAr68usRm"
      },
      "source": [
        "# Word2Vec\n",
        "here I implement word2vec with very simple example using tensorflow  \n",
        "word2vec is vector representation for words with similarity\n",
        "\n",
        "\n",
        "    2020.11.16\n",
        "\n",
        "    Minsuk Heo's code taken (and adapted) from\n",
        "    https://github.com/minsuk-heo/python_tutorial/blob/master/data_science/nlp/word2vec_tensorflow.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pts9zf0PusRt"
      },
      "source": [
        "# Collect Data\n",
        "we will use only 10 sentences to create word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP9vAWXSusRv"
      },
      "source": [
        "corpus = ['king is a strong man', \n",
        "          'queen is a wise woman', \n",
        "          'boy is a young man',\n",
        "          'girl is a young woman',\n",
        "          'prince is a young king',\n",
        "          'princess is a young queen',\n",
        "          'man is strong', \n",
        "          'woman is pretty',\n",
        "          'prince is a boy will be king',\n",
        "          'princess is a girl will be queen']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvv4bjFIusR0"
      },
      "source": [
        "# Remove stop words\n",
        "In order for efficiency of creating word vector, we will remove commonly used words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4zTeKemusR1"
      },
      "source": [
        "def remove_stop_words(corpus):\n",
        "    stop_words = ['is', 'a', 'will', 'be']\n",
        "    results = []\n",
        "    for text in corpus:\n",
        "        tmp = text.split(' ')\n",
        "        for stop_word in stop_words:\n",
        "            if stop_word in tmp:\n",
        "                tmp.remove(stop_word)\n",
        "        results.append(\" \".join(tmp))\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoQwDJC5usR6",
        "outputId": "ad9411e2-b075-441b-f575-6b8d3060ff7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpus = remove_stop_words(corpus)\n",
        "# [s.split() for s in corpus]\n",
        "corpus"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king strong man',\n",
              " 'queen wise woman',\n",
              " 'boy young man',\n",
              " 'girl young woman',\n",
              " 'prince young king',\n",
              " 'princess young queen',\n",
              " 'man strong',\n",
              " 'woman pretty',\n",
              " 'prince boy king',\n",
              " 'princess girl queen']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkU3968wusSA"
      },
      "source": [
        "words = []\n",
        "for text in corpus:\n",
        "    for word in text.split(' '):\n",
        "        words.append(word)\n",
        "\n",
        "words = set(words)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnG-kR_qusSG"
      },
      "source": [
        "here we have word set by which we will have word vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1c9HZ50usSH",
        "outputId": "0e3fbcb7-ec6f-48d4-8677-2e345c637be9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Number of words =',len(words))\n",
        "words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words = 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy',\n",
              " 'girl',\n",
              " 'king',\n",
              " 'man',\n",
              " 'pretty',\n",
              " 'prince',\n",
              " 'princess',\n",
              " 'queen',\n",
              " 'strong',\n",
              " 'wise',\n",
              " 'woman',\n",
              " 'young'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJsodjQBusSN"
      },
      "source": [
        "# data generation\n",
        "we will generate label for each word using skip gram.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkzT9b1RusSO"
      },
      "source": [
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "    \n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMN36vQngK8m",
        "outputId": "98b8b2cd-6d49-4746-f4fd-a9b309be1b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word2int"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy': 8,\n",
              " 'girl': 9,\n",
              " 'king': 11,\n",
              " 'man': 6,\n",
              " 'pretty': 5,\n",
              " 'prince': 0,\n",
              " 'princess': 10,\n",
              " 'queen': 2,\n",
              " 'strong': 3,\n",
              " 'wise': 1,\n",
              " 'woman': 7,\n",
              " 'young': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "razsR93CusSR",
        "outputId": "48d62aef-677b-45e8-f7b8-30e1969c0364",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "for text in corpus:\n",
        "    print(text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king strong man\n",
            "queen wise woman\n",
            "boy young man\n",
            "girl young woman\n",
            "prince young king\n",
            "princess young queen\n",
            "man strong\n",
            "woman pretty\n",
            "prince boy king\n",
            "princess girl queen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlPOH-tTusSV",
        "outputId": "71764278-76ae-4432-e311-cf033d6d1f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['input', 'label'])\n",
        "print('df.shape =', df.shape)\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df.shape = (52, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>king</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>king</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>strong</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strong</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    input   label\n",
              "0    king  strong\n",
              "1    king     man\n",
              "2  strong    king\n",
              "3  strong     man\n",
              "4     man    king"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tGt_1ZPusSZ",
        "outputId": "b9395591-e0e8-4ca9-e71c-41c0bfbdaffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb1YKNZkusSc",
        "outputId": "3d998bd8-ff1b-460c-8720-22d103edf820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word2int"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy': 8,\n",
              " 'girl': 9,\n",
              " 'king': 11,\n",
              " 'man': 6,\n",
              " 'pretty': 5,\n",
              " 'prince': 0,\n",
              " 'princess': 10,\n",
              " 'queen': 2,\n",
              " 'strong': 3,\n",
              " 'wise': 1,\n",
              " 'woman': 7,\n",
              " 'young': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLJolL7U9Kv2",
        "outputId": "d17a209d-8199-48eb-b781-0317f5004c72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "w2idx = pd.DataFrame.from_dict({ 'values': word2int.values(), 'word': word2int.keys() })\n",
        "w2idx"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>prince</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>queen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>young</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>pretty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>boy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>girl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>princess</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    values      word\n",
              "0        0    prince\n",
              "1        1      wise\n",
              "2        2     queen\n",
              "3        3    strong\n",
              "4        4     young\n",
              "5        5    pretty\n",
              "6        6       man\n",
              "7        7     woman\n",
              "8        8       boy\n",
              "9        9      girl\n",
              "10      10  princess\n",
              "11      11      king"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDBDS3oNusSf"
      },
      "source": [
        "# Define Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE9tfOWRerK6",
        "outputId": "adfae8ff-2887-4e2c-81ba-7f368e96d744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "ONE_HOT_DIM = len(words)\n",
        "print('ONE_HOT_DIM = ', ONE_HOT_DIM)\n",
        "# function to convert numbers to one hot vectors\n",
        "def to_one_hot_encoding(data_point_index):\n",
        "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "    one_hot_encoding[data_point_index] = 1\n",
        "    return one_hot_encoding\n",
        "\n",
        "X = [] # input word\n",
        "Y = [] # target word"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ONE_HOT_DIM =  12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdkH0En5cTjn",
        "outputId": "42231c96-8512-4b6f-df13-a9fa7b3b92ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(df.head())\n",
        "\n",
        "for x, y in zip(df['input'], df['label']):\n",
        "    Xtmp = to_one_hot_encoding(word2int[ x ])\n",
        "    Ytmp = to_one_hot_encoding(word2int[ y ])\n",
        "    print(x,'\\t has place =',word2int[ x ],'\\t===>',Xtmp, '\\t\\t\\t\\t',  y ,'===>',Ytmp)\n",
        "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
        "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
        "\n",
        "# convert them to numpy arrays\n",
        "X_train = np.asarray(X)\n",
        "Y_train = np.asarray(Y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    input   label\n",
            "0    king  strong\n",
            "1    king     man\n",
            "2  strong    king\n",
            "3  strong     man\n",
            "4     man    king\n",
            "king \t has place = 11 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \t\t\t\t strong ===> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "king \t has place = 11 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \t\t\t\t man ===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "strong \t has place = 3 \t===> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t king ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "strong \t has place = 3 \t===> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t man ===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "man \t has place = 6 \t===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \t\t\t\t king ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "man \t has place = 6 \t===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \t\t\t\t strong ===> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "queen \t has place = 2 \t===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t wise ===> [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "queen \t has place = 2 \t===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t woman ===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "wise \t has place = 1 \t===> [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t queen ===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "wise \t has place = 1 \t===> [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t woman ===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "woman \t has place = 7 \t===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \t\t\t\t queen ===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "woman \t has place = 7 \t===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \t\t\t\t wise ===> [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "boy \t has place = 8 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "boy \t has place = 8 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] \t\t\t\t man ===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t boy ===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t man ===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "man \t has place = 6 \t===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \t\t\t\t boy ===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "man \t has place = 6 \t===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "girl \t has place = 9 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "girl \t has place = 9 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] \t\t\t\t woman ===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t girl ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t woman ===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "woman \t has place = 7 \t===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \t\t\t\t girl ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "woman \t has place = 7 \t===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "prince \t has place = 0 \t===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "prince \t has place = 0 \t===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t king ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t prince ===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t king ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "king \t has place = 11 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \t\t\t\t prince ===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "king \t has place = 11 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "princess \t has place = 10 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "princess \t has place = 10 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] \t\t\t\t queen ===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t princess ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "young \t has place = 4 \t===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t queen ===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "queen \t has place = 2 \t===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t princess ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "queen \t has place = 2 \t===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t young ===> [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "man \t has place = 6 \t===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] \t\t\t\t strong ===> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "strong \t has place = 3 \t===> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t man ===> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            "woman \t has place = 7 \t===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \t\t\t\t pretty ===> [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            "pretty \t has place = 5 \t===> [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] \t\t\t\t woman ===> [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "prince \t has place = 0 \t===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t boy ===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "prince \t has place = 0 \t===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t king ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "boy \t has place = 8 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] \t\t\t\t prince ===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "boy \t has place = 8 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] \t\t\t\t king ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "king \t has place = 11 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \t\t\t\t prince ===> [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "king \t has place = 11 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] \t\t\t\t boy ===> [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            "princess \t has place = 10 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] \t\t\t\t girl ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "princess \t has place = 10 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] \t\t\t\t queen ===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "girl \t has place = 9 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] \t\t\t\t princess ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "girl \t has place = 9 \t===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] \t\t\t\t queen ===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "queen \t has place = 2 \t===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t princess ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "queen \t has place = 2 \t===> [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \t\t\t\t girl ===> [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imynaAvYcVxS",
        "outputId": "f0e83be8-9b23-4338-c884-1b7100660622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Num of entries in X = ',len(X_train))\n",
        "print('show first three entires in X:\\n',X_train[:3])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of entries in X =  52\n",
            "show first three entires in X:\n",
            " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC_BHy_x0WS_"
      },
      "source": [
        "# pd.options.display.max_rows\n",
        "pd.options.display.max_columns = 50\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-gjyedYdQo6",
        "outputId": "e15d4066-770b-4528-b251-bc104b5df210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df['X_train']=list(X_train)\n",
        "df['Y_train']=list(Y_train)\n",
        "\n",
        "pd.set_option('display.width', 1000)\n",
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "      <th>X_train</th>\n",
              "      <th>Y_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>king</td>\n",
              "      <td>strong</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>king</td>\n",
              "      <td>man</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>strong</td>\n",
              "      <td>king</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strong</td>\n",
              "      <td>man</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man</td>\n",
              "      <td>king</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    input   label                                            X_train                                            Y_train\n",
              "0    king  strong  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "1    king     man  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
              "2  strong    king  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "3  strong     man  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...\n",
              "4     man    king  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60R2jPLS36kC"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers \n",
        "\n",
        "network = models.Sequential()\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
        "# network.add( layers.Dense(2, activation='relu', input_shape=(12,) ) )\n",
        "network.add( layers.Dense(2, activation='linear', input_shape=(12,) ) )\n",
        "\n",
        "network.add( layers.Dense(12, activation='softmax' ) )\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXUipZZ36t7"
      },
      "source": [
        "network.compile( optimizer='rmsprop', \n",
        "                 loss = 'categorical_crossentropy', \n",
        "                 metrics = ['accuracy'] )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TcLc-6Z362N",
        "outputId": "05a7787d-03e9-4a73-acaf-a66ec816cd1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network.fit( X_train, Y_train, epochs=2000, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "52/52 [==============================] - 0s 780us/step - loss: 2.1286 - accuracy: 0.2500\n",
            "Epoch 2/2000\n",
            "52/52 [==============================] - 0s 878us/step - loss: 2.1266 - accuracy: 0.2500\n",
            "Epoch 3/2000\n",
            "52/52 [==============================] - 0s 921us/step - loss: 2.1235 - accuracy: 0.2500\n",
            "Epoch 4/2000\n",
            "52/52 [==============================] - 0s 752us/step - loss: 2.1209 - accuracy: 0.2500\n",
            "Epoch 5/2000\n",
            "52/52 [==============================] - 0s 742us/step - loss: 2.1176 - accuracy: 0.2500\n",
            "Epoch 6/2000\n",
            "52/52 [==============================] - 0s 726us/step - loss: 2.1153 - accuracy: 0.2500\n",
            "Epoch 7/2000\n",
            "52/52 [==============================] - 0s 795us/step - loss: 2.1129 - accuracy: 0.2500\n",
            "Epoch 8/2000\n",
            "52/52 [==============================] - 0s 716us/step - loss: 2.1098 - accuracy: 0.2692\n",
            "Epoch 9/2000\n",
            "52/52 [==============================] - 0s 742us/step - loss: 2.1076 - accuracy: 0.2692\n",
            "Epoch 10/2000\n",
            "52/52 [==============================] - 0s 758us/step - loss: 2.1050 - accuracy: 0.2500\n",
            "Epoch 11/2000\n",
            "52/52 [==============================] - 0s 908us/step - loss: 2.1022 - accuracy: 0.2308\n",
            "Epoch 12/2000\n",
            "52/52 [==============================] - 0s 909us/step - loss: 2.0994 - accuracy: 0.2500\n",
            "Epoch 13/2000\n",
            "52/52 [==============================] - 0s 734us/step - loss: 2.0970 - accuracy: 0.2500\n",
            "Epoch 14/2000\n",
            "52/52 [==============================] - 0s 706us/step - loss: 2.0945 - accuracy: 0.2500\n",
            "Epoch 15/2000\n",
            "52/52 [==============================] - 0s 830us/step - loss: 2.0920 - accuracy: 0.2500\n",
            "Epoch 16/2000\n",
            "52/52 [==============================] - 0s 734us/step - loss: 2.0893 - accuracy: 0.2308\n",
            "Epoch 17/2000\n",
            "52/52 [==============================] - 0s 711us/step - loss: 2.0874 - accuracy: 0.2500\n",
            "Epoch 18/2000\n",
            "52/52 [==============================] - 0s 715us/step - loss: 2.0852 - accuracy: 0.2500\n",
            "Epoch 19/2000\n",
            "52/52 [==============================] - 0s 748us/step - loss: 2.0824 - accuracy: 0.2692\n",
            "Epoch 20/2000\n",
            "52/52 [==============================] - 0s 779us/step - loss: 2.0796 - accuracy: 0.2115\n",
            "Epoch 21/2000\n",
            "52/52 [==============================] - 0s 741us/step - loss: 2.0774 - accuracy: 0.2500\n",
            "Epoch 22/2000\n",
            "52/52 [==============================] - 0s 766us/step - loss: 2.0745 - accuracy: 0.2692\n",
            "Epoch 23/2000\n",
            "52/52 [==============================] - 0s 762us/step - loss: 2.0727 - accuracy: 0.2692\n",
            "Epoch 24/2000\n",
            "52/52 [==============================] - 0s 754us/step - loss: 2.0700 - accuracy: 0.2692\n",
            "Epoch 25/2000\n",
            "52/52 [==============================] - 0s 794us/step - loss: 2.0683 - accuracy: 0.2692\n",
            "Epoch 26/2000\n",
            "52/52 [==============================] - 0s 737us/step - loss: 2.0659 - accuracy: 0.2308\n",
            "Epoch 27/2000\n",
            "52/52 [==============================] - 0s 716us/step - loss: 2.0632 - accuracy: 0.2500\n",
            "Epoch 28/2000\n",
            "52/52 [==============================] - 0s 717us/step - loss: 2.0615 - accuracy: 0.2308\n",
            "Epoch 29/2000\n",
            "52/52 [==============================] - 0s 846us/step - loss: 2.0597 - accuracy: 0.2500\n",
            "Epoch 30/2000\n",
            "52/52 [==============================] - 0s 720us/step - loss: 2.0574 - accuracy: 0.2308\n",
            "Epoch 31/2000\n",
            "52/52 [==============================] - 0s 740us/step - loss: 2.0562 - accuracy: 0.2500\n",
            "Epoch 32/2000\n",
            "52/52 [==============================] - 0s 762us/step - loss: 2.0543 - accuracy: 0.2500\n",
            "Epoch 33/2000\n",
            "52/52 [==============================] - 0s 812us/step - loss: 2.0516 - accuracy: 0.2500\n",
            "Epoch 34/2000\n",
            "52/52 [==============================] - 0s 815us/step - loss: 2.0499 - accuracy: 0.2500\n",
            "Epoch 35/2000\n",
            "52/52 [==============================] - 0s 989us/step - loss: 2.0480 - accuracy: 0.2500\n",
            "Epoch 36/2000\n",
            "52/52 [==============================] - 0s 781us/step - loss: 2.0458 - accuracy: 0.2308\n",
            "Epoch 37/2000\n",
            "52/52 [==============================] - 0s 732us/step - loss: 2.0434 - accuracy: 0.2692\n",
            "Epoch 38/2000\n",
            "52/52 [==============================] - 0s 770us/step - loss: 2.0419 - accuracy: 0.2692\n",
            "Epoch 39/2000\n",
            "52/52 [==============================] - 0s 741us/step - loss: 2.0403 - accuracy: 0.2500\n",
            "Epoch 40/2000\n",
            "52/52 [==============================] - 0s 749us/step - loss: 2.0382 - accuracy: 0.2500\n",
            "Epoch 41/2000\n",
            "52/52 [==============================] - 0s 723us/step - loss: 2.0361 - accuracy: 0.2308\n",
            "Epoch 42/2000\n",
            "52/52 [==============================] - 0s 752us/step - loss: 2.0334 - accuracy: 0.2308\n",
            "Epoch 43/2000\n",
            "52/52 [==============================] - 0s 812us/step - loss: 2.0319 - accuracy: 0.2500\n",
            "Epoch 44/2000\n",
            "52/52 [==============================] - 0s 729us/step - loss: 2.0308 - accuracy: 0.2500\n",
            "Epoch 45/2000\n",
            "52/52 [==============================] - 0s 741us/step - loss: 2.0281 - accuracy: 0.2308\n",
            "Epoch 46/2000\n",
            "52/52 [==============================] - 0s 779us/step - loss: 2.0262 - accuracy: 0.2308\n",
            "Epoch 47/2000\n",
            "52/52 [==============================] - 0s 752us/step - loss: 2.0252 - accuracy: 0.2692\n",
            "Epoch 48/2000\n",
            "52/52 [==============================] - 0s 806us/step - loss: 2.0239 - accuracy: 0.2308\n",
            "Epoch 49/2000\n",
            "52/52 [==============================] - 0s 781us/step - loss: 2.0221 - accuracy: 0.2500\n",
            "Epoch 50/2000\n",
            "52/52 [==============================] - 0s 844us/step - loss: 2.0200 - accuracy: 0.2500\n",
            "Epoch 51/2000\n",
            "52/52 [==============================] - 0s 750us/step - loss: 2.0184 - accuracy: 0.2500\n",
            "Epoch 52/2000\n",
            "52/52 [==============================] - 0s 759us/step - loss: 2.0168 - accuracy: 0.2500\n",
            "Epoch 53/2000\n",
            "52/52 [==============================] - 0s 817us/step - loss: 2.0150 - accuracy: 0.2500\n",
            "Epoch 54/2000\n",
            "52/52 [==============================] - 0s 767us/step - loss: 2.0130 - accuracy: 0.2308\n",
            "Epoch 55/2000\n",
            "52/52 [==============================] - 0s 763us/step - loss: 2.0125 - accuracy: 0.2500\n",
            "Epoch 56/2000\n",
            "52/52 [==============================] - 0s 788us/step - loss: 2.0101 - accuracy: 0.2115\n",
            "Epoch 57/2000\n",
            "52/52 [==============================] - 0s 871us/step - loss: 2.0079 - accuracy: 0.2692\n",
            "Epoch 58/2000\n",
            "52/52 [==============================] - 0s 768us/step - loss: 2.0064 - accuracy: 0.2692\n",
            "Epoch 59/2000\n",
            "52/52 [==============================] - 0s 779us/step - loss: 2.0053 - accuracy: 0.2500\n",
            "Epoch 60/2000\n",
            "52/52 [==============================] - 0s 732us/step - loss: 2.0037 - accuracy: 0.2692\n",
            "Epoch 61/2000\n",
            "52/52 [==============================] - 0s 757us/step - loss: 2.0016 - accuracy: 0.2692\n",
            "Epoch 62/2000\n",
            "52/52 [==============================] - 0s 701us/step - loss: 1.9998 - accuracy: 0.2692\n",
            "Epoch 63/2000\n",
            "52/52 [==============================] - 0s 719us/step - loss: 1.9982 - accuracy: 0.2692\n",
            "Epoch 64/2000\n",
            "52/52 [==============================] - 0s 898us/step - loss: 1.9964 - accuracy: 0.2692\n",
            "Epoch 65/2000\n",
            "52/52 [==============================] - 0s 808us/step - loss: 1.9948 - accuracy: 0.2692\n",
            "Epoch 66/2000\n",
            "52/52 [==============================] - 0s 801us/step - loss: 1.9928 - accuracy: 0.2692\n",
            "Epoch 67/2000\n",
            "52/52 [==============================] - 0s 729us/step - loss: 1.9917 - accuracy: 0.2692\n",
            "Epoch 68/2000\n",
            "52/52 [==============================] - 0s 753us/step - loss: 1.9903 - accuracy: 0.2692\n",
            "Epoch 69/2000\n",
            "52/52 [==============================] - 0s 803us/step - loss: 1.9887 - accuracy: 0.2692\n",
            "Epoch 70/2000\n",
            "52/52 [==============================] - 0s 766us/step - loss: 1.9873 - accuracy: 0.2692\n",
            "Epoch 71/2000\n",
            "52/52 [==============================] - 0s 730us/step - loss: 1.9864 - accuracy: 0.2692\n",
            "Epoch 72/2000\n",
            "52/52 [==============================] - 0s 731us/step - loss: 1.9851 - accuracy: 0.2692\n",
            "Epoch 73/2000\n",
            "52/52 [==============================] - 0s 770us/step - loss: 1.9834 - accuracy: 0.2692\n",
            "Epoch 74/2000\n",
            "52/52 [==============================] - 0s 765us/step - loss: 1.9826 - accuracy: 0.2692\n",
            "Epoch 75/2000\n",
            "52/52 [==============================] - 0s 751us/step - loss: 1.9807 - accuracy: 0.2692\n",
            "Epoch 76/2000\n",
            "52/52 [==============================] - 0s 805us/step - loss: 1.9791 - accuracy: 0.2692\n",
            "Epoch 77/2000\n",
            "52/52 [==============================] - 0s 733us/step - loss: 1.9774 - accuracy: 0.2692\n",
            "Epoch 78/2000\n",
            "52/52 [==============================] - 0s 774us/step - loss: 1.9757 - accuracy: 0.2692\n",
            "Epoch 79/2000\n",
            "52/52 [==============================] - 0s 744us/step - loss: 1.9748 - accuracy: 0.2692\n",
            "Epoch 80/2000\n",
            "52/52 [==============================] - 0s 776us/step - loss: 1.9729 - accuracy: 0.2692\n",
            "Epoch 81/2000\n",
            "52/52 [==============================] - 0s 790us/step - loss: 1.9720 - accuracy: 0.2692\n",
            "Epoch 82/2000\n",
            "52/52 [==============================] - 0s 795us/step - loss: 1.9708 - accuracy: 0.2692\n",
            "Epoch 83/2000\n",
            "52/52 [==============================] - 0s 836us/step - loss: 1.9697 - accuracy: 0.2692\n",
            "Epoch 84/2000\n",
            "52/52 [==============================] - 0s 730us/step - loss: 1.9688 - accuracy: 0.2692\n",
            "Epoch 85/2000\n",
            "52/52 [==============================] - 0s 761us/step - loss: 1.9673 - accuracy: 0.2692\n",
            "Epoch 86/2000\n",
            "52/52 [==============================] - 0s 715us/step - loss: 1.9661 - accuracy: 0.2692\n",
            "Epoch 87/2000\n",
            "52/52 [==============================] - 0s 760us/step - loss: 1.9648 - accuracy: 0.2692\n",
            "Epoch 88/2000\n",
            "52/52 [==============================] - 0s 795us/step - loss: 1.9634 - accuracy: 0.2692\n",
            "Epoch 89/2000\n",
            "52/52 [==============================] - 0s 723us/step - loss: 1.9620 - accuracy: 0.2692\n",
            "Epoch 90/2000\n",
            "52/52 [==============================] - 0s 807us/step - loss: 1.9608 - accuracy: 0.2692\n",
            "Epoch 91/2000\n",
            "52/52 [==============================] - 0s 715us/step - loss: 1.9598 - accuracy: 0.2692\n",
            "Epoch 92/2000\n",
            "52/52 [==============================] - 0s 764us/step - loss: 1.9587 - accuracy: 0.2692\n",
            "Epoch 93/2000\n",
            "52/52 [==============================] - 0s 749us/step - loss: 1.9574 - accuracy: 0.2692\n",
            "Epoch 94/2000\n",
            "52/52 [==============================] - 0s 842us/step - loss: 1.9567 - accuracy: 0.2692\n",
            "Epoch 95/2000\n",
            "52/52 [==============================] - 0s 804us/step - loss: 1.9547 - accuracy: 0.2692\n",
            "Epoch 96/2000\n",
            "52/52 [==============================] - 0s 796us/step - loss: 1.9536 - accuracy: 0.2692\n",
            "Epoch 97/2000\n",
            "52/52 [==============================] - 0s 810us/step - loss: 1.9525 - accuracy: 0.2692\n",
            "Epoch 98/2000\n",
            "52/52 [==============================] - 0s 753us/step - loss: 1.9522 - accuracy: 0.2692\n",
            "Epoch 99/2000\n",
            "52/52 [==============================] - 0s 709us/step - loss: 1.9508 - accuracy: 0.2692\n",
            "Epoch 100/2000\n",
            "52/52 [==============================] - 0s 763us/step - loss: 1.9499 - accuracy: 0.2692\n",
            "Epoch 101/2000\n",
            "52/52 [==============================] - 0s 724us/step - loss: 1.9495 - accuracy: 0.2692\n",
            "Epoch 102/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.9481 - accuracy: 0.2692\n",
            "Epoch 103/2000\n",
            "52/52 [==============================] - 0s 809us/step - loss: 1.9467 - accuracy: 0.2692\n",
            "Epoch 104/2000\n",
            "52/52 [==============================] - 0s 707us/step - loss: 1.9462 - accuracy: 0.2692\n",
            "Epoch 105/2000\n",
            "52/52 [==============================] - 0s 870us/step - loss: 1.9446 - accuracy: 0.2692\n",
            "Epoch 106/2000\n",
            "52/52 [==============================] - 0s 761us/step - loss: 1.9439 - accuracy: 0.2692\n",
            "Epoch 107/2000\n",
            "52/52 [==============================] - 0s 771us/step - loss: 1.9424 - accuracy: 0.2692\n",
            "Epoch 108/2000\n",
            "52/52 [==============================] - 0s 805us/step - loss: 1.9410 - accuracy: 0.2692\n",
            "Epoch 109/2000\n",
            "52/52 [==============================] - 0s 744us/step - loss: 1.9405 - accuracy: 0.2692\n",
            "Epoch 110/2000\n",
            "52/52 [==============================] - 0s 769us/step - loss: 1.9398 - accuracy: 0.2692\n",
            "Epoch 111/2000\n",
            "52/52 [==============================] - 0s 735us/step - loss: 1.9383 - accuracy: 0.2692\n",
            "Epoch 112/2000\n",
            "52/52 [==============================] - 0s 791us/step - loss: 1.9383 - accuracy: 0.2692\n",
            "Epoch 113/2000\n",
            "52/52 [==============================] - 0s 755us/step - loss: 1.9367 - accuracy: 0.2692\n",
            "Epoch 114/2000\n",
            "52/52 [==============================] - 0s 751us/step - loss: 1.9356 - accuracy: 0.2692\n",
            "Epoch 115/2000\n",
            "52/52 [==============================] - 0s 782us/step - loss: 1.9342 - accuracy: 0.2692\n",
            "Epoch 116/2000\n",
            "52/52 [==============================] - 0s 863us/step - loss: 1.9330 - accuracy: 0.2692\n",
            "Epoch 117/2000\n",
            "52/52 [==============================] - 0s 769us/step - loss: 1.9317 - accuracy: 0.2692\n",
            "Epoch 118/2000\n",
            "52/52 [==============================] - 0s 710us/step - loss: 1.9309 - accuracy: 0.2692\n",
            "Epoch 119/2000\n",
            "52/52 [==============================] - 0s 740us/step - loss: 1.9304 - accuracy: 0.2692\n",
            "Epoch 120/2000\n",
            "52/52 [==============================] - 0s 713us/step - loss: 1.9298 - accuracy: 0.2692\n",
            "Epoch 121/2000\n",
            "52/52 [==============================] - 0s 786us/step - loss: 1.9281 - accuracy: 0.2692\n",
            "Epoch 122/2000\n",
            "52/52 [==============================] - 0s 748us/step - loss: 1.9279 - accuracy: 0.2692\n",
            "Epoch 123/2000\n",
            "52/52 [==============================] - 0s 823us/step - loss: 1.9267 - accuracy: 0.2692\n",
            "Epoch 124/2000\n",
            "52/52 [==============================] - 0s 924us/step - loss: 1.9261 - accuracy: 0.2692\n",
            "Epoch 125/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.9249 - accuracy: 0.2692\n",
            "Epoch 126/2000\n",
            "52/52 [==============================] - 0s 773us/step - loss: 1.9255 - accuracy: 0.2692\n",
            "Epoch 127/2000\n",
            "52/52 [==============================] - 0s 766us/step - loss: 1.9234 - accuracy: 0.2692\n",
            "Epoch 128/2000\n",
            "52/52 [==============================] - 0s 746us/step - loss: 1.9236 - accuracy: 0.2692\n",
            "Epoch 129/2000\n",
            "52/52 [==============================] - 0s 747us/step - loss: 1.9225 - accuracy: 0.2692\n",
            "Epoch 130/2000\n",
            "52/52 [==============================] - 0s 757us/step - loss: 1.9215 - accuracy: 0.2692\n",
            "Epoch 131/2000\n",
            "52/52 [==============================] - 0s 721us/step - loss: 1.9203 - accuracy: 0.2692\n",
            "Epoch 132/2000\n",
            "52/52 [==============================] - 0s 781us/step - loss: 1.9202 - accuracy: 0.2692\n",
            "Epoch 133/2000\n",
            "52/52 [==============================] - 0s 921us/step - loss: 1.9189 - accuracy: 0.2692\n",
            "Epoch 134/2000\n",
            "52/52 [==============================] - 0s 824us/step - loss: 1.9194 - accuracy: 0.2692\n",
            "Epoch 135/2000\n",
            "52/52 [==============================] - 0s 751us/step - loss: 1.9178 - accuracy: 0.2692\n",
            "Epoch 136/2000\n",
            "52/52 [==============================] - 0s 778us/step - loss: 1.9169 - accuracy: 0.2692\n",
            "Epoch 137/2000\n",
            "52/52 [==============================] - 0s 736us/step - loss: 1.9167 - accuracy: 0.2692\n",
            "Epoch 138/2000\n",
            "52/52 [==============================] - 0s 744us/step - loss: 1.9157 - accuracy: 0.2692\n",
            "Epoch 139/2000\n",
            "52/52 [==============================] - 0s 765us/step - loss: 1.9145 - accuracy: 0.2692\n",
            "Epoch 140/2000\n",
            "52/52 [==============================] - 0s 717us/step - loss: 1.9133 - accuracy: 0.2692\n",
            "Epoch 141/2000\n",
            "52/52 [==============================] - 0s 916us/step - loss: 1.9127 - accuracy: 0.2692\n",
            "Epoch 142/2000\n",
            "52/52 [==============================] - 0s 844us/step - loss: 1.9125 - accuracy: 0.2692\n",
            "Epoch 143/2000\n",
            "52/52 [==============================] - 0s 759us/step - loss: 1.9116 - accuracy: 0.2692\n",
            "Epoch 144/2000\n",
            "52/52 [==============================] - 0s 761us/step - loss: 1.9108 - accuracy: 0.2692\n",
            "Epoch 145/2000\n",
            "52/52 [==============================] - 0s 742us/step - loss: 1.9102 - accuracy: 0.2692\n",
            "Epoch 146/2000\n",
            "52/52 [==============================] - 0s 927us/step - loss: 1.9092 - accuracy: 0.2692\n",
            "Epoch 147/2000\n",
            "52/52 [==============================] - 0s 788us/step - loss: 1.9087 - accuracy: 0.2692\n",
            "Epoch 148/2000\n",
            "52/52 [==============================] - 0s 810us/step - loss: 1.9076 - accuracy: 0.2692\n",
            "Epoch 149/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.9072 - accuracy: 0.2692\n",
            "Epoch 150/2000\n",
            "52/52 [==============================] - 0s 866us/step - loss: 1.9062 - accuracy: 0.2692\n",
            "Epoch 151/2000\n",
            "52/52 [==============================] - 0s 796us/step - loss: 1.9070 - accuracy: 0.2692\n",
            "Epoch 152/2000\n",
            "52/52 [==============================] - 0s 806us/step - loss: 1.9059 - accuracy: 0.2692\n",
            "Epoch 153/2000\n",
            "52/52 [==============================] - 0s 774us/step - loss: 1.9052 - accuracy: 0.2692\n",
            "Epoch 154/2000\n",
            "52/52 [==============================] - 0s 737us/step - loss: 1.9048 - accuracy: 0.2692\n",
            "Epoch 155/2000\n",
            "52/52 [==============================] - 0s 810us/step - loss: 1.9043 - accuracy: 0.2692\n",
            "Epoch 156/2000\n",
            "52/52 [==============================] - 0s 844us/step - loss: 1.9035 - accuracy: 0.2692\n",
            "Epoch 157/2000\n",
            "52/52 [==============================] - 0s 820us/step - loss: 1.9032 - accuracy: 0.2692\n",
            "Epoch 158/2000\n",
            "52/52 [==============================] - 0s 788us/step - loss: 1.9029 - accuracy: 0.2692\n",
            "Epoch 159/2000\n",
            "52/52 [==============================] - 0s 741us/step - loss: 1.9015 - accuracy: 0.2692\n",
            "Epoch 160/2000\n",
            "52/52 [==============================] - 0s 738us/step - loss: 1.9015 - accuracy: 0.2692\n",
            "Epoch 161/2000\n",
            "52/52 [==============================] - 0s 784us/step - loss: 1.9011 - accuracy: 0.2692\n",
            "Epoch 162/2000\n",
            "52/52 [==============================] - 0s 876us/step - loss: 1.9008 - accuracy: 0.2692\n",
            "Epoch 163/2000\n",
            "52/52 [==============================] - 0s 830us/step - loss: 1.9003 - accuracy: 0.2692\n",
            "Epoch 164/2000\n",
            "52/52 [==============================] - 0s 811us/step - loss: 1.8989 - accuracy: 0.2692\n",
            "Epoch 165/2000\n",
            "52/52 [==============================] - 0s 802us/step - loss: 1.8985 - accuracy: 0.2500\n",
            "Epoch 166/2000\n",
            "52/52 [==============================] - 0s 746us/step - loss: 1.8984 - accuracy: 0.2692\n",
            "Epoch 167/2000\n",
            "52/52 [==============================] - 0s 774us/step - loss: 1.8979 - accuracy: 0.2692\n",
            "Epoch 168/2000\n",
            "52/52 [==============================] - 0s 831us/step - loss: 1.8972 - accuracy: 0.2500\n",
            "Epoch 169/2000\n",
            "52/52 [==============================] - 0s 850us/step - loss: 1.8968 - accuracy: 0.2692\n",
            "Epoch 170/2000\n",
            "52/52 [==============================] - 0s 885us/step - loss: 1.8958 - accuracy: 0.2692\n",
            "Epoch 171/2000\n",
            "52/52 [==============================] - 0s 807us/step - loss: 1.8962 - accuracy: 0.2692\n",
            "Epoch 172/2000\n",
            "52/52 [==============================] - 0s 786us/step - loss: 1.8949 - accuracy: 0.2500\n",
            "Epoch 173/2000\n",
            "52/52 [==============================] - 0s 807us/step - loss: 1.8937 - accuracy: 0.2692\n",
            "Epoch 174/2000\n",
            "52/52 [==============================] - 0s 802us/step - loss: 1.8938 - accuracy: 0.2692\n",
            "Epoch 175/2000\n",
            "52/52 [==============================] - 0s 811us/step - loss: 1.8933 - accuracy: 0.2885\n",
            "Epoch 176/2000\n",
            "52/52 [==============================] - 0s 794us/step - loss: 1.8932 - accuracy: 0.2692\n",
            "Epoch 177/2000\n",
            "52/52 [==============================] - 0s 757us/step - loss: 1.8936 - accuracy: 0.2692\n",
            "Epoch 178/2000\n",
            "52/52 [==============================] - 0s 823us/step - loss: 1.8932 - accuracy: 0.2885\n",
            "Epoch 179/2000\n",
            "52/52 [==============================] - 0s 724us/step - loss: 1.8922 - accuracy: 0.2500\n",
            "Epoch 180/2000\n",
            "52/52 [==============================] - 0s 818us/step - loss: 1.8924 - accuracy: 0.2500\n",
            "Epoch 181/2000\n",
            "52/52 [==============================] - 0s 781us/step - loss: 1.8916 - accuracy: 0.2692\n",
            "Epoch 182/2000\n",
            "52/52 [==============================] - 0s 759us/step - loss: 1.8904 - accuracy: 0.2692\n",
            "Epoch 183/2000\n",
            "52/52 [==============================] - 0s 820us/step - loss: 1.8908 - accuracy: 0.2500\n",
            "Epoch 184/2000\n",
            "52/52 [==============================] - 0s 812us/step - loss: 1.8896 - accuracy: 0.2500\n",
            "Epoch 185/2000\n",
            "52/52 [==============================] - 0s 816us/step - loss: 1.8894 - accuracy: 0.2692\n",
            "Epoch 186/2000\n",
            "52/52 [==============================] - 0s 815us/step - loss: 1.8895 - accuracy: 0.2885\n",
            "Epoch 187/2000\n",
            "52/52 [==============================] - 0s 802us/step - loss: 1.8891 - accuracy: 0.2692\n",
            "Epoch 188/2000\n",
            "52/52 [==============================] - 0s 749us/step - loss: 1.8881 - accuracy: 0.2500\n",
            "Epoch 189/2000\n",
            "52/52 [==============================] - 0s 894us/step - loss: 1.8878 - accuracy: 0.2692\n",
            "Epoch 190/2000\n",
            "52/52 [==============================] - 0s 743us/step - loss: 1.8870 - accuracy: 0.2885\n",
            "Epoch 191/2000\n",
            "52/52 [==============================] - 0s 776us/step - loss: 1.8868 - accuracy: 0.2692\n",
            "Epoch 192/2000\n",
            "52/52 [==============================] - 0s 880us/step - loss: 1.8864 - accuracy: 0.2692\n",
            "Epoch 193/2000\n",
            "52/52 [==============================] - 0s 856us/step - loss: 1.8861 - accuracy: 0.2885\n",
            "Epoch 194/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8857 - accuracy: 0.2885\n",
            "Epoch 195/2000\n",
            "52/52 [==============================] - 0s 881us/step - loss: 1.8851 - accuracy: 0.2885\n",
            "Epoch 196/2000\n",
            "52/52 [==============================] - 0s 802us/step - loss: 1.8849 - accuracy: 0.2885\n",
            "Epoch 197/2000\n",
            "52/52 [==============================] - 0s 801us/step - loss: 1.8845 - accuracy: 0.2885\n",
            "Epoch 198/2000\n",
            "52/52 [==============================] - 0s 900us/step - loss: 1.8843 - accuracy: 0.2885\n",
            "Epoch 199/2000\n",
            "52/52 [==============================] - 0s 792us/step - loss: 1.8828 - accuracy: 0.2692\n",
            "Epoch 200/2000\n",
            "52/52 [==============================] - 0s 830us/step - loss: 1.8835 - accuracy: 0.2885\n",
            "Epoch 201/2000\n",
            "52/52 [==============================] - 0s 814us/step - loss: 1.8829 - accuracy: 0.2885\n",
            "Epoch 202/2000\n",
            "52/52 [==============================] - 0s 910us/step - loss: 1.8820 - accuracy: 0.2885\n",
            "Epoch 203/2000\n",
            "52/52 [==============================] - 0s 843us/step - loss: 1.8818 - accuracy: 0.2885\n",
            "Epoch 204/2000\n",
            "52/52 [==============================] - 0s 767us/step - loss: 1.8816 - accuracy: 0.2885\n",
            "Epoch 205/2000\n",
            "52/52 [==============================] - 0s 726us/step - loss: 1.8813 - accuracy: 0.2885\n",
            "Epoch 206/2000\n",
            "52/52 [==============================] - 0s 770us/step - loss: 1.8811 - accuracy: 0.2885\n",
            "Epoch 207/2000\n",
            "52/52 [==============================] - 0s 763us/step - loss: 1.8800 - accuracy: 0.2885\n",
            "Epoch 208/2000\n",
            "52/52 [==============================] - 0s 792us/step - loss: 1.8794 - accuracy: 0.2885\n",
            "Epoch 209/2000\n",
            "52/52 [==============================] - 0s 833us/step - loss: 1.8797 - accuracy: 0.2885\n",
            "Epoch 210/2000\n",
            "52/52 [==============================] - 0s 909us/step - loss: 1.8790 - accuracy: 0.2885\n",
            "Epoch 211/2000\n",
            "52/52 [==============================] - 0s 784us/step - loss: 1.8777 - accuracy: 0.2885\n",
            "Epoch 212/2000\n",
            "52/52 [==============================] - 0s 884us/step - loss: 1.8782 - accuracy: 0.2885\n",
            "Epoch 213/2000\n",
            "52/52 [==============================] - 0s 846us/step - loss: 1.8775 - accuracy: 0.2885\n",
            "Epoch 214/2000\n",
            "52/52 [==============================] - 0s 760us/step - loss: 1.8773 - accuracy: 0.2885\n",
            "Epoch 215/2000\n",
            "52/52 [==============================] - 0s 766us/step - loss: 1.8775 - accuracy: 0.2885\n",
            "Epoch 216/2000\n",
            "52/52 [==============================] - 0s 744us/step - loss: 1.8768 - accuracy: 0.2885\n",
            "Epoch 217/2000\n",
            "52/52 [==============================] - 0s 875us/step - loss: 1.8763 - accuracy: 0.2885\n",
            "Epoch 218/2000\n",
            "52/52 [==============================] - 0s 826us/step - loss: 1.8765 - accuracy: 0.2885\n",
            "Epoch 219/2000\n",
            "52/52 [==============================] - 0s 851us/step - loss: 1.8758 - accuracy: 0.2885\n",
            "Epoch 220/2000\n",
            "52/52 [==============================] - 0s 765us/step - loss: 1.8751 - accuracy: 0.2885\n",
            "Epoch 221/2000\n",
            "52/52 [==============================] - 0s 763us/step - loss: 1.8750 - accuracy: 0.2885\n",
            "Epoch 222/2000\n",
            "52/52 [==============================] - 0s 836us/step - loss: 1.8744 - accuracy: 0.2885\n",
            "Epoch 223/2000\n",
            "52/52 [==============================] - 0s 796us/step - loss: 1.8739 - accuracy: 0.2885\n",
            "Epoch 224/2000\n",
            "52/52 [==============================] - 0s 730us/step - loss: 1.8738 - accuracy: 0.2885\n",
            "Epoch 225/2000\n",
            "52/52 [==============================] - 0s 756us/step - loss: 1.8727 - accuracy: 0.2885\n",
            "Epoch 226/2000\n",
            "52/52 [==============================] - 0s 871us/step - loss: 1.8728 - accuracy: 0.2885\n",
            "Epoch 227/2000\n",
            "52/52 [==============================] - 0s 822us/step - loss: 1.8720 - accuracy: 0.2885\n",
            "Epoch 228/2000\n",
            "52/52 [==============================] - 0s 860us/step - loss: 1.8720 - accuracy: 0.2885\n",
            "Epoch 229/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8719 - accuracy: 0.2885\n",
            "Epoch 230/2000\n",
            "52/52 [==============================] - 0s 850us/step - loss: 1.8723 - accuracy: 0.2885\n",
            "Epoch 231/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8709 - accuracy: 0.2885\n",
            "Epoch 232/2000\n",
            "52/52 [==============================] - 0s 896us/step - loss: 1.8723 - accuracy: 0.2885\n",
            "Epoch 233/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8708 - accuracy: 0.2885\n",
            "Epoch 234/2000\n",
            "52/52 [==============================] - 0s 793us/step - loss: 1.8705 - accuracy: 0.2885\n",
            "Epoch 235/2000\n",
            "52/52 [==============================] - 0s 913us/step - loss: 1.8701 - accuracy: 0.2885\n",
            "Epoch 236/2000\n",
            "52/52 [==============================] - 0s 883us/step - loss: 1.8704 - accuracy: 0.2885\n",
            "Epoch 237/2000\n",
            "52/52 [==============================] - 0s 844us/step - loss: 1.8699 - accuracy: 0.2885\n",
            "Epoch 238/2000\n",
            "52/52 [==============================] - 0s 811us/step - loss: 1.8691 - accuracy: 0.2885\n",
            "Epoch 239/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8684 - accuracy: 0.2885\n",
            "Epoch 240/2000\n",
            "52/52 [==============================] - 0s 799us/step - loss: 1.8687 - accuracy: 0.2885\n",
            "Epoch 241/2000\n",
            "52/52 [==============================] - 0s 762us/step - loss: 1.8685 - accuracy: 0.2885\n",
            "Epoch 242/2000\n",
            "52/52 [==============================] - 0s 776us/step - loss: 1.8682 - accuracy: 0.2885\n",
            "Epoch 243/2000\n",
            "52/52 [==============================] - 0s 860us/step - loss: 1.8670 - accuracy: 0.2885\n",
            "Epoch 244/2000\n",
            "52/52 [==============================] - 0s 857us/step - loss: 1.8674 - accuracy: 0.2885\n",
            "Epoch 245/2000\n",
            "52/52 [==============================] - 0s 869us/step - loss: 1.8675 - accuracy: 0.2885\n",
            "Epoch 246/2000\n",
            "52/52 [==============================] - 0s 794us/step - loss: 1.8669 - accuracy: 0.2885\n",
            "Epoch 247/2000\n",
            "52/52 [==============================] - 0s 856us/step - loss: 1.8672 - accuracy: 0.2885\n",
            "Epoch 248/2000\n",
            "52/52 [==============================] - 0s 808us/step - loss: 1.8661 - accuracy: 0.2885\n",
            "Epoch 249/2000\n",
            "52/52 [==============================] - 0s 782us/step - loss: 1.8661 - accuracy: 0.2885\n",
            "Epoch 250/2000\n",
            "52/52 [==============================] - 0s 753us/step - loss: 1.8657 - accuracy: 0.2885\n",
            "Epoch 251/2000\n",
            "52/52 [==============================] - 0s 942us/step - loss: 1.8656 - accuracy: 0.2885\n",
            "Epoch 252/2000\n",
            "52/52 [==============================] - 0s 777us/step - loss: 1.8649 - accuracy: 0.2885\n",
            "Epoch 253/2000\n",
            "52/52 [==============================] - 0s 961us/step - loss: 1.8637 - accuracy: 0.2885\n",
            "Epoch 254/2000\n",
            "52/52 [==============================] - 0s 780us/step - loss: 1.8641 - accuracy: 0.2885\n",
            "Epoch 255/2000\n",
            "52/52 [==============================] - 0s 857us/step - loss: 1.8636 - accuracy: 0.2885\n",
            "Epoch 256/2000\n",
            "52/52 [==============================] - 0s 827us/step - loss: 1.8635 - accuracy: 0.2885\n",
            "Epoch 257/2000\n",
            "52/52 [==============================] - 0s 836us/step - loss: 1.8628 - accuracy: 0.2885\n",
            "Epoch 258/2000\n",
            "52/52 [==============================] - 0s 785us/step - loss: 1.8639 - accuracy: 0.2885\n",
            "Epoch 259/2000\n",
            "52/52 [==============================] - 0s 945us/step - loss: 1.8630 - accuracy: 0.2885\n",
            "Epoch 260/2000\n",
            "52/52 [==============================] - 0s 875us/step - loss: 1.8635 - accuracy: 0.2885\n",
            "Epoch 261/2000\n",
            "52/52 [==============================] - 0s 837us/step - loss: 1.8623 - accuracy: 0.2885\n",
            "Epoch 262/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8630 - accuracy: 0.2885\n",
            "Epoch 263/2000\n",
            "52/52 [==============================] - 0s 874us/step - loss: 1.8614 - accuracy: 0.2885\n",
            "Epoch 264/2000\n",
            "52/52 [==============================] - 0s 780us/step - loss: 1.8624 - accuracy: 0.2885\n",
            "Epoch 265/2000\n",
            "52/52 [==============================] - 0s 781us/step - loss: 1.8617 - accuracy: 0.2885\n",
            "Epoch 266/2000\n",
            "52/52 [==============================] - 0s 948us/step - loss: 1.8609 - accuracy: 0.2885\n",
            "Epoch 267/2000\n",
            "52/52 [==============================] - 0s 778us/step - loss: 1.8609 - accuracy: 0.2885\n",
            "Epoch 268/2000\n",
            "52/52 [==============================] - 0s 896us/step - loss: 1.8599 - accuracy: 0.2885\n",
            "Epoch 269/2000\n",
            "52/52 [==============================] - 0s 892us/step - loss: 1.8605 - accuracy: 0.2885\n",
            "Epoch 270/2000\n",
            "52/52 [==============================] - 0s 807us/step - loss: 1.8600 - accuracy: 0.2885\n",
            "Epoch 271/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8595 - accuracy: 0.2885\n",
            "Epoch 272/2000\n",
            "52/52 [==============================] - 0s 890us/step - loss: 1.8597 - accuracy: 0.2885\n",
            "Epoch 273/2000\n",
            "52/52 [==============================] - 0s 884us/step - loss: 1.8599 - accuracy: 0.2885\n",
            "Epoch 274/2000\n",
            "52/52 [==============================] - 0s 815us/step - loss: 1.8605 - accuracy: 0.2885\n",
            "Epoch 275/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8597 - accuracy: 0.2885\n",
            "Epoch 276/2000\n",
            "52/52 [==============================] - 0s 853us/step - loss: 1.8591 - accuracy: 0.2885\n",
            "Epoch 277/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8600 - accuracy: 0.2885\n",
            "Epoch 278/2000\n",
            "52/52 [==============================] - 0s 851us/step - loss: 1.8591 - accuracy: 0.2885\n",
            "Epoch 279/2000\n",
            "52/52 [==============================] - 0s 832us/step - loss: 1.8588 - accuracy: 0.2885\n",
            "Epoch 280/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8595 - accuracy: 0.2885\n",
            "Epoch 281/2000\n",
            "52/52 [==============================] - 0s 772us/step - loss: 1.8590 - accuracy: 0.2885\n",
            "Epoch 282/2000\n",
            "52/52 [==============================] - 0s 771us/step - loss: 1.8590 - accuracy: 0.2885\n",
            "Epoch 283/2000\n",
            "52/52 [==============================] - 0s 742us/step - loss: 1.8584 - accuracy: 0.2885\n",
            "Epoch 284/2000\n",
            "52/52 [==============================] - 0s 790us/step - loss: 1.8580 - accuracy: 0.2885\n",
            "Epoch 285/2000\n",
            "52/52 [==============================] - 0s 844us/step - loss: 1.8583 - accuracy: 0.2885\n",
            "Epoch 286/2000\n",
            "52/52 [==============================] - 0s 833us/step - loss: 1.8582 - accuracy: 0.2885\n",
            "Epoch 287/2000\n",
            "52/52 [==============================] - 0s 878us/step - loss: 1.8578 - accuracy: 0.2885\n",
            "Epoch 288/2000\n",
            "52/52 [==============================] - 0s 873us/step - loss: 1.8575 - accuracy: 0.2885\n",
            "Epoch 289/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8573 - accuracy: 0.2885\n",
            "Epoch 290/2000\n",
            "52/52 [==============================] - 0s 775us/step - loss: 1.8571 - accuracy: 0.2885\n",
            "Epoch 291/2000\n",
            "52/52 [==============================] - 0s 947us/step - loss: 1.8561 - accuracy: 0.2885\n",
            "Epoch 292/2000\n",
            "52/52 [==============================] - 0s 937us/step - loss: 1.8564 - accuracy: 0.2885\n",
            "Epoch 293/2000\n",
            "52/52 [==============================] - 0s 829us/step - loss: 1.8568 - accuracy: 0.2885\n",
            "Epoch 294/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8563 - accuracy: 0.2885\n",
            "Epoch 295/2000\n",
            "52/52 [==============================] - 0s 782us/step - loss: 1.8562 - accuracy: 0.2885\n",
            "Epoch 296/2000\n",
            "52/52 [==============================] - 0s 798us/step - loss: 1.8569 - accuracy: 0.2885\n",
            "Epoch 297/2000\n",
            "52/52 [==============================] - 0s 837us/step - loss: 1.8567 - accuracy: 0.2885\n",
            "Epoch 298/2000\n",
            "52/52 [==============================] - 0s 848us/step - loss: 1.8560 - accuracy: 0.2885\n",
            "Epoch 299/2000\n",
            "52/52 [==============================] - 0s 726us/step - loss: 1.8559 - accuracy: 0.2885\n",
            "Epoch 300/2000\n",
            "52/52 [==============================] - 0s 894us/step - loss: 1.8571 - accuracy: 0.2885\n",
            "Epoch 301/2000\n",
            "52/52 [==============================] - 0s 859us/step - loss: 1.8549 - accuracy: 0.2885\n",
            "Epoch 302/2000\n",
            "52/52 [==============================] - 0s 775us/step - loss: 1.8552 - accuracy: 0.2885\n",
            "Epoch 303/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8557 - accuracy: 0.2885\n",
            "Epoch 304/2000\n",
            "52/52 [==============================] - 0s 937us/step - loss: 1.8543 - accuracy: 0.2885\n",
            "Epoch 305/2000\n",
            "52/52 [==============================] - 0s 899us/step - loss: 1.8543 - accuracy: 0.2885\n",
            "Epoch 306/2000\n",
            "52/52 [==============================] - 0s 802us/step - loss: 1.8546 - accuracy: 0.2885\n",
            "Epoch 307/2000\n",
            "52/52 [==============================] - 0s 824us/step - loss: 1.8538 - accuracy: 0.2885\n",
            "Epoch 308/2000\n",
            "52/52 [==============================] - 0s 935us/step - loss: 1.8541 - accuracy: 0.2885\n",
            "Epoch 309/2000\n",
            "52/52 [==============================] - 0s 849us/step - loss: 1.8537 - accuracy: 0.2885\n",
            "Epoch 310/2000\n",
            "52/52 [==============================] - 0s 773us/step - loss: 1.8534 - accuracy: 0.2885\n",
            "Epoch 311/2000\n",
            "52/52 [==============================] - 0s 939us/step - loss: 1.8538 - accuracy: 0.2885\n",
            "Epoch 312/2000\n",
            "52/52 [==============================] - 0s 956us/step - loss: 1.8532 - accuracy: 0.2885\n",
            "Epoch 313/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8526 - accuracy: 0.2885\n",
            "Epoch 314/2000\n",
            "52/52 [==============================] - 0s 903us/step - loss: 1.8520 - accuracy: 0.2885\n",
            "Epoch 315/2000\n",
            "52/52 [==============================] - 0s 942us/step - loss: 1.8527 - accuracy: 0.2885\n",
            "Epoch 316/2000\n",
            "52/52 [==============================] - 0s 870us/step - loss: 1.8533 - accuracy: 0.2885\n",
            "Epoch 317/2000\n",
            "52/52 [==============================] - 0s 767us/step - loss: 1.8525 - accuracy: 0.2885\n",
            "Epoch 318/2000\n",
            "52/52 [==============================] - 0s 903us/step - loss: 1.8529 - accuracy: 0.2885\n",
            "Epoch 319/2000\n",
            "52/52 [==============================] - 0s 800us/step - loss: 1.8524 - accuracy: 0.2885\n",
            "Epoch 320/2000\n",
            "52/52 [==============================] - 0s 960us/step - loss: 1.8526 - accuracy: 0.2885\n",
            "Epoch 321/2000\n",
            "52/52 [==============================] - 0s 839us/step - loss: 1.8519 - accuracy: 0.2885\n",
            "Epoch 322/2000\n",
            "52/52 [==============================] - 0s 910us/step - loss: 1.8526 - accuracy: 0.2885\n",
            "Epoch 323/2000\n",
            "52/52 [==============================] - 0s 825us/step - loss: 1.8519 - accuracy: 0.2885\n",
            "Epoch 324/2000\n",
            "52/52 [==============================] - 0s 781us/step - loss: 1.8515 - accuracy: 0.2885\n",
            "Epoch 325/2000\n",
            "52/52 [==============================] - 0s 906us/step - loss: 1.8514 - accuracy: 0.2885\n",
            "Epoch 326/2000\n",
            "52/52 [==============================] - 0s 803us/step - loss: 1.8520 - accuracy: 0.2885\n",
            "Epoch 327/2000\n",
            "52/52 [==============================] - 0s 870us/step - loss: 1.8513 - accuracy: 0.2885\n",
            "Epoch 328/2000\n",
            "52/52 [==============================] - 0s 918us/step - loss: 1.8514 - accuracy: 0.2885\n",
            "Epoch 329/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8513 - accuracy: 0.2885\n",
            "Epoch 330/2000\n",
            "52/52 [==============================] - 0s 883us/step - loss: 1.8510 - accuracy: 0.2885\n",
            "Epoch 331/2000\n",
            "52/52 [==============================] - 0s 838us/step - loss: 1.8509 - accuracy: 0.2885\n",
            "Epoch 332/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8507 - accuracy: 0.2885\n",
            "Epoch 333/2000\n",
            "52/52 [==============================] - 0s 854us/step - loss: 1.8503 - accuracy: 0.2885\n",
            "Epoch 334/2000\n",
            "52/52 [==============================] - 0s 895us/step - loss: 1.8507 - accuracy: 0.2885\n",
            "Epoch 335/2000\n",
            "52/52 [==============================] - 0s 804us/step - loss: 1.8517 - accuracy: 0.2885\n",
            "Epoch 336/2000\n",
            "52/52 [==============================] - 0s 856us/step - loss: 1.8506 - accuracy: 0.2885\n",
            "Epoch 337/2000\n",
            "52/52 [==============================] - 0s 832us/step - loss: 1.8513 - accuracy: 0.2885\n",
            "Epoch 338/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8513 - accuracy: 0.2885\n",
            "Epoch 339/2000\n",
            "52/52 [==============================] - 0s 862us/step - loss: 1.8510 - accuracy: 0.2885\n",
            "Epoch 340/2000\n",
            "52/52 [==============================] - 0s 863us/step - loss: 1.8511 - accuracy: 0.2885\n",
            "Epoch 341/2000\n",
            "52/52 [==============================] - 0s 763us/step - loss: 1.8508 - accuracy: 0.2885\n",
            "Epoch 342/2000\n",
            "52/52 [==============================] - 0s 879us/step - loss: 1.8512 - accuracy: 0.2885\n",
            "Epoch 343/2000\n",
            "52/52 [==============================] - 0s 807us/step - loss: 1.8504 - accuracy: 0.2885\n",
            "Epoch 344/2000\n",
            "52/52 [==============================] - 0s 890us/step - loss: 1.8500 - accuracy: 0.2885\n",
            "Epoch 345/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8501 - accuracy: 0.2885\n",
            "Epoch 346/2000\n",
            "52/52 [==============================] - 0s 835us/step - loss: 1.8497 - accuracy: 0.2885\n",
            "Epoch 347/2000\n",
            "52/52 [==============================] - 0s 832us/step - loss: 1.8499 - accuracy: 0.2885\n",
            "Epoch 348/2000\n",
            "52/52 [==============================] - 0s 913us/step - loss: 1.8503 - accuracy: 0.2885\n",
            "Epoch 349/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8492 - accuracy: 0.2885\n",
            "Epoch 350/2000\n",
            "52/52 [==============================] - 0s 842us/step - loss: 1.8506 - accuracy: 0.2500\n",
            "Epoch 351/2000\n",
            "52/52 [==============================] - 0s 956us/step - loss: 1.8495 - accuracy: 0.2692\n",
            "Epoch 352/2000\n",
            "52/52 [==============================] - 0s 920us/step - loss: 1.8488 - accuracy: 0.2692\n",
            "Epoch 353/2000\n",
            "52/52 [==============================] - 0s 858us/step - loss: 1.8496 - accuracy: 0.2885\n",
            "Epoch 354/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8500 - accuracy: 0.2885\n",
            "Epoch 355/2000\n",
            "52/52 [==============================] - 0s 910us/step - loss: 1.8489 - accuracy: 0.2885\n",
            "Epoch 356/2000\n",
            "52/52 [==============================] - 0s 831us/step - loss: 1.8485 - accuracy: 0.2885\n",
            "Epoch 357/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8488 - accuracy: 0.2885\n",
            "Epoch 358/2000\n",
            "52/52 [==============================] - 0s 835us/step - loss: 1.8484 - accuracy: 0.2885\n",
            "Epoch 359/2000\n",
            "52/52 [==============================] - 0s 825us/step - loss: 1.8475 - accuracy: 0.2885\n",
            "Epoch 360/2000\n",
            "52/52 [==============================] - 0s 772us/step - loss: 1.8486 - accuracy: 0.2692\n",
            "Epoch 361/2000\n",
            "52/52 [==============================] - 0s 828us/step - loss: 1.8479 - accuracy: 0.2885\n",
            "Epoch 362/2000\n",
            "52/52 [==============================] - 0s 923us/step - loss: 1.8477 - accuracy: 0.2885\n",
            "Epoch 363/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8471 - accuracy: 0.2885\n",
            "Epoch 364/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8473 - accuracy: 0.2885\n",
            "Epoch 365/2000\n",
            "52/52 [==============================] - 0s 924us/step - loss: 1.8468 - accuracy: 0.2885\n",
            "Epoch 366/2000\n",
            "52/52 [==============================] - 0s 855us/step - loss: 1.8462 - accuracy: 0.2885\n",
            "Epoch 367/2000\n",
            "52/52 [==============================] - 0s 931us/step - loss: 1.8467 - accuracy: 0.2885\n",
            "Epoch 368/2000\n",
            "52/52 [==============================] - 0s 839us/step - loss: 1.8460 - accuracy: 0.2885\n",
            "Epoch 369/2000\n",
            "52/52 [==============================] - 0s 931us/step - loss: 1.8458 - accuracy: 0.2885\n",
            "Epoch 370/2000\n",
            "52/52 [==============================] - 0s 906us/step - loss: 1.8458 - accuracy: 0.2885\n",
            "Epoch 371/2000\n",
            "52/52 [==============================] - 0s 928us/step - loss: 1.8463 - accuracy: 0.2885\n",
            "Epoch 372/2000\n",
            "52/52 [==============================] - 0s 943us/step - loss: 1.8470 - accuracy: 0.2885\n",
            "Epoch 373/2000\n",
            "52/52 [==============================] - 0s 811us/step - loss: 1.8460 - accuracy: 0.2885\n",
            "Epoch 374/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8464 - accuracy: 0.2885\n",
            "Epoch 375/2000\n",
            "52/52 [==============================] - 0s 826us/step - loss: 1.8467 - accuracy: 0.2885\n",
            "Epoch 376/2000\n",
            "52/52 [==============================] - 0s 843us/step - loss: 1.8469 - accuracy: 0.2885\n",
            "Epoch 377/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8463 - accuracy: 0.2885\n",
            "Epoch 378/2000\n",
            "52/52 [==============================] - 0s 881us/step - loss: 1.8456 - accuracy: 0.2885\n",
            "Epoch 379/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8455 - accuracy: 0.2885\n",
            "Epoch 380/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8458 - accuracy: 0.2885\n",
            "Epoch 381/2000\n",
            "52/52 [==============================] - 0s 806us/step - loss: 1.8458 - accuracy: 0.2885\n",
            "Epoch 382/2000\n",
            "52/52 [==============================] - 0s 870us/step - loss: 1.8460 - accuracy: 0.2885\n",
            "Epoch 383/2000\n",
            "52/52 [==============================] - 0s 885us/step - loss: 1.8457 - accuracy: 0.2885\n",
            "Epoch 384/2000\n",
            "52/52 [==============================] - 0s 767us/step - loss: 1.8455 - accuracy: 0.2885\n",
            "Epoch 385/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8464 - accuracy: 0.2885\n",
            "Epoch 386/2000\n",
            "52/52 [==============================] - 0s 822us/step - loss: 1.8445 - accuracy: 0.2885\n",
            "Epoch 387/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8456 - accuracy: 0.2885\n",
            "Epoch 388/2000\n",
            "52/52 [==============================] - 0s 771us/step - loss: 1.8457 - accuracy: 0.2885\n",
            "Epoch 389/2000\n",
            "52/52 [==============================] - 0s 828us/step - loss: 1.8455 - accuracy: 0.2885\n",
            "Epoch 390/2000\n",
            "52/52 [==============================] - 0s 930us/step - loss: 1.8455 - accuracy: 0.2885\n",
            "Epoch 391/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8454 - accuracy: 0.2885\n",
            "Epoch 392/2000\n",
            "52/52 [==============================] - 0s 832us/step - loss: 1.8464 - accuracy: 0.2692\n",
            "Epoch 393/2000\n",
            "52/52 [==============================] - 0s 953us/step - loss: 1.8457 - accuracy: 0.2885\n",
            "Epoch 394/2000\n",
            "52/52 [==============================] - 0s 872us/step - loss: 1.8452 - accuracy: 0.2885\n",
            "Epoch 395/2000\n",
            "52/52 [==============================] - 0s 812us/step - loss: 1.8466 - accuracy: 0.2885\n",
            "Epoch 396/2000\n",
            "52/52 [==============================] - 0s 918us/step - loss: 1.8465 - accuracy: 0.2885\n",
            "Epoch 397/2000\n",
            "52/52 [==============================] - 0s 813us/step - loss: 1.8472 - accuracy: 0.2885\n",
            "Epoch 398/2000\n",
            "52/52 [==============================] - 0s 943us/step - loss: 1.8471 - accuracy: 0.2885\n",
            "Epoch 399/2000\n",
            "52/52 [==============================] - 0s 834us/step - loss: 1.8469 - accuracy: 0.2885\n",
            "Epoch 400/2000\n",
            "52/52 [==============================] - 0s 947us/step - loss: 1.8474 - accuracy: 0.2692\n",
            "Epoch 401/2000\n",
            "52/52 [==============================] - 0s 912us/step - loss: 1.8470 - accuracy: 0.2885\n",
            "Epoch 402/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8465 - accuracy: 0.2885\n",
            "Epoch 403/2000\n",
            "52/52 [==============================] - 0s 838us/step - loss: 1.8474 - accuracy: 0.2885\n",
            "Epoch 404/2000\n",
            "52/52 [==============================] - 0s 795us/step - loss: 1.8464 - accuracy: 0.2885\n",
            "Epoch 405/2000\n",
            "52/52 [==============================] - 0s 965us/step - loss: 1.8468 - accuracy: 0.2885\n",
            "Epoch 406/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8476 - accuracy: 0.2885\n",
            "Epoch 407/2000\n",
            "52/52 [==============================] - 0s 877us/step - loss: 1.8468 - accuracy: 0.2885\n",
            "Epoch 408/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8462 - accuracy: 0.2692\n",
            "Epoch 409/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8462 - accuracy: 0.2885\n",
            "Epoch 410/2000\n",
            "52/52 [==============================] - 0s 838us/step - loss: 1.8463 - accuracy: 0.2885\n",
            "Epoch 411/2000\n",
            "52/52 [==============================] - 0s 905us/step - loss: 1.8455 - accuracy: 0.2885\n",
            "Epoch 412/2000\n",
            "52/52 [==============================] - 0s 880us/step - loss: 1.8459 - accuracy: 0.2885\n",
            "Epoch 413/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8456 - accuracy: 0.2885\n",
            "Epoch 414/2000\n",
            "52/52 [==============================] - 0s 814us/step - loss: 1.8463 - accuracy: 0.2692\n",
            "Epoch 415/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8466 - accuracy: 0.2885\n",
            "Epoch 416/2000\n",
            "52/52 [==============================] - 0s 996us/step - loss: 1.8459 - accuracy: 0.2885\n",
            "Epoch 417/2000\n",
            "52/52 [==============================] - 0s 835us/step - loss: 1.8471 - accuracy: 0.2885\n",
            "Epoch 418/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8469 - accuracy: 0.2692\n",
            "Epoch 419/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8468 - accuracy: 0.2692\n",
            "Epoch 420/2000\n",
            "52/52 [==============================] - 0s 987us/step - loss: 1.8483 - accuracy: 0.2500\n",
            "Epoch 421/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8473 - accuracy: 0.2500\n",
            "Epoch 422/2000\n",
            "52/52 [==============================] - 0s 887us/step - loss: 1.8483 - accuracy: 0.2885\n",
            "Epoch 423/2000\n",
            "52/52 [==============================] - 0s 949us/step - loss: 1.8484 - accuracy: 0.2692\n",
            "Epoch 424/2000\n",
            "52/52 [==============================] - 0s 889us/step - loss: 1.8472 - accuracy: 0.2500\n",
            "Epoch 425/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8470 - accuracy: 0.2692\n",
            "Epoch 426/2000\n",
            "52/52 [==============================] - 0s 900us/step - loss: 1.8469 - accuracy: 0.2885\n",
            "Epoch 427/2000\n",
            "52/52 [==============================] - 0s 865us/step - loss: 1.8461 - accuracy: 0.2692\n",
            "Epoch 428/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8459 - accuracy: 0.2692\n",
            "Epoch 429/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8451 - accuracy: 0.2692\n",
            "Epoch 430/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8462 - accuracy: 0.2500\n",
            "Epoch 431/2000\n",
            "52/52 [==============================] - 0s 878us/step - loss: 1.8455 - accuracy: 0.2692\n",
            "Epoch 432/2000\n",
            "52/52 [==============================] - 0s 847us/step - loss: 1.8449 - accuracy: 0.2692\n",
            "Epoch 433/2000\n",
            "52/52 [==============================] - 0s 805us/step - loss: 1.8457 - accuracy: 0.2692\n",
            "Epoch 434/2000\n",
            "52/52 [==============================] - 0s 894us/step - loss: 1.8456 - accuracy: 0.2500\n",
            "Epoch 435/2000\n",
            "52/52 [==============================] - 0s 866us/step - loss: 1.8451 - accuracy: 0.2500\n",
            "Epoch 436/2000\n",
            "52/52 [==============================] - 0s 892us/step - loss: 1.8455 - accuracy: 0.2885\n",
            "Epoch 437/2000\n",
            "52/52 [==============================] - 0s 838us/step - loss: 1.8456 - accuracy: 0.2692\n",
            "Epoch 438/2000\n",
            "52/52 [==============================] - 0s 915us/step - loss: 1.8452 - accuracy: 0.2885\n",
            "Epoch 439/2000\n",
            "52/52 [==============================] - 0s 861us/step - loss: 1.8450 - accuracy: 0.2692\n",
            "Epoch 440/2000\n",
            "52/52 [==============================] - 0s 832us/step - loss: 1.8443 - accuracy: 0.2885\n",
            "Epoch 441/2000\n",
            "52/52 [==============================] - 0s 925us/step - loss: 1.8442 - accuracy: 0.2692\n",
            "Epoch 442/2000\n",
            "52/52 [==============================] - 0s 928us/step - loss: 1.8445 - accuracy: 0.2692\n",
            "Epoch 443/2000\n",
            "52/52 [==============================] - 0s 864us/step - loss: 1.8439 - accuracy: 0.2885\n",
            "Epoch 444/2000\n",
            "52/52 [==============================] - 0s 860us/step - loss: 1.8443 - accuracy: 0.2885\n",
            "Epoch 445/2000\n",
            "52/52 [==============================] - 0s 871us/step - loss: 1.8447 - accuracy: 0.2692\n",
            "Epoch 446/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8443 - accuracy: 0.2885\n",
            "Epoch 447/2000\n",
            "52/52 [==============================] - 0s 849us/step - loss: 1.8446 - accuracy: 0.2500\n",
            "Epoch 448/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8444 - accuracy: 0.2692\n",
            "Epoch 449/2000\n",
            "52/52 [==============================] - 0s 920us/step - loss: 1.8436 - accuracy: 0.2692\n",
            "Epoch 450/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8432 - accuracy: 0.2500\n",
            "Epoch 451/2000\n",
            "52/52 [==============================] - 0s 875us/step - loss: 1.8429 - accuracy: 0.2500\n",
            "Epoch 452/2000\n",
            "52/52 [==============================] - 0s 959us/step - loss: 1.8441 - accuracy: 0.2500\n",
            "Epoch 453/2000\n",
            "52/52 [==============================] - 0s 815us/step - loss: 1.8435 - accuracy: 0.2500\n",
            "Epoch 454/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8425 - accuracy: 0.2500\n",
            "Epoch 455/2000\n",
            "52/52 [==============================] - 0s 899us/step - loss: 1.8427 - accuracy: 0.2885\n",
            "Epoch 456/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8416 - accuracy: 0.2500\n",
            "Epoch 457/2000\n",
            "52/52 [==============================] - 0s 879us/step - loss: 1.8428 - accuracy: 0.2500\n",
            "Epoch 458/2000\n",
            "52/52 [==============================] - 0s 907us/step - loss: 1.8424 - accuracy: 0.2692\n",
            "Epoch 459/2000\n",
            "52/52 [==============================] - 0s 960us/step - loss: 1.8424 - accuracy: 0.2885\n",
            "Epoch 460/2000\n",
            "52/52 [==============================] - 0s 834us/step - loss: 1.8426 - accuracy: 0.2885\n",
            "Epoch 461/2000\n",
            "52/52 [==============================] - 0s 860us/step - loss: 1.8427 - accuracy: 0.2692\n",
            "Epoch 462/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8417 - accuracy: 0.2308\n",
            "Epoch 463/2000\n",
            "52/52 [==============================] - 0s 939us/step - loss: 1.8422 - accuracy: 0.2308\n",
            "Epoch 464/2000\n",
            "52/52 [==============================] - 0s 959us/step - loss: 1.8425 - accuracy: 0.2692\n",
            "Epoch 465/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8422 - accuracy: 0.2692\n",
            "Epoch 466/2000\n",
            "52/52 [==============================] - 0s 909us/step - loss: 1.8416 - accuracy: 0.2500\n",
            "Epoch 467/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8423 - accuracy: 0.2692\n",
            "Epoch 468/2000\n",
            "52/52 [==============================] - 0s 867us/step - loss: 1.8424 - accuracy: 0.2500\n",
            "Epoch 469/2000\n",
            "52/52 [==============================] - 0s 998us/step - loss: 1.8423 - accuracy: 0.2692\n",
            "Epoch 470/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8422 - accuracy: 0.2500\n",
            "Epoch 471/2000\n",
            "52/52 [==============================] - 0s 880us/step - loss: 1.8422 - accuracy: 0.2692\n",
            "Epoch 472/2000\n",
            "52/52 [==============================] - 0s 896us/step - loss: 1.8421 - accuracy: 0.2500\n",
            "Epoch 473/2000\n",
            "52/52 [==============================] - 0s 888us/step - loss: 1.8422 - accuracy: 0.2885\n",
            "Epoch 474/2000\n",
            "52/52 [==============================] - 0s 933us/step - loss: 1.8417 - accuracy: 0.2692\n",
            "Epoch 475/2000\n",
            "52/52 [==============================] - 0s 804us/step - loss: 1.8427 - accuracy: 0.2692\n",
            "Epoch 476/2000\n",
            "52/52 [==============================] - 0s 904us/step - loss: 1.8420 - accuracy: 0.2500\n",
            "Epoch 477/2000\n",
            "52/52 [==============================] - 0s 880us/step - loss: 1.8428 - accuracy: 0.2692\n",
            "Epoch 478/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8438 - accuracy: 0.2692\n",
            "Epoch 479/2000\n",
            "52/52 [==============================] - 0s 787us/step - loss: 1.8433 - accuracy: 0.2692\n",
            "Epoch 480/2000\n",
            "52/52 [==============================] - 0s 862us/step - loss: 1.8427 - accuracy: 0.2692\n",
            "Epoch 481/2000\n",
            "52/52 [==============================] - 0s 918us/step - loss: 1.8430 - accuracy: 0.2692\n",
            "Epoch 482/2000\n",
            "52/52 [==============================] - 0s 903us/step - loss: 1.8428 - accuracy: 0.2692\n",
            "Epoch 483/2000\n",
            "52/52 [==============================] - 0s 849us/step - loss: 1.8426 - accuracy: 0.2692\n",
            "Epoch 484/2000\n",
            "52/52 [==============================] - 0s 924us/step - loss: 1.8440 - accuracy: 0.2692\n",
            "Epoch 485/2000\n",
            "52/52 [==============================] - 0s 886us/step - loss: 1.8419 - accuracy: 0.2692\n",
            "Epoch 486/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8424 - accuracy: 0.2692\n",
            "Epoch 487/2000\n",
            "52/52 [==============================] - 0s 840us/step - loss: 1.8422 - accuracy: 0.2692\n",
            "Epoch 488/2000\n",
            "52/52 [==============================] - 0s 856us/step - loss: 1.8425 - accuracy: 0.2692\n",
            "Epoch 489/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8428 - accuracy: 0.2692\n",
            "Epoch 490/2000\n",
            "52/52 [==============================] - 0s 839us/step - loss: 1.8428 - accuracy: 0.2692\n",
            "Epoch 491/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8424 - accuracy: 0.2692\n",
            "Epoch 492/2000\n",
            "52/52 [==============================] - 0s 960us/step - loss: 1.8427 - accuracy: 0.2692\n",
            "Epoch 493/2000\n",
            "52/52 [==============================] - 0s 913us/step - loss: 1.8421 - accuracy: 0.2692\n",
            "Epoch 494/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8419 - accuracy: 0.2692\n",
            "Epoch 495/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8412 - accuracy: 0.2692\n",
            "Epoch 496/2000\n",
            "52/52 [==============================] - 0s 917us/step - loss: 1.8405 - accuracy: 0.2692\n",
            "Epoch 497/2000\n",
            "52/52 [==============================] - 0s 896us/step - loss: 1.8408 - accuracy: 0.2692\n",
            "Epoch 498/2000\n",
            "52/52 [==============================] - 0s 927us/step - loss: 1.8413 - accuracy: 0.2500\n",
            "Epoch 499/2000\n",
            "52/52 [==============================] - 0s 857us/step - loss: 1.8406 - accuracy: 0.2308\n",
            "Epoch 500/2000\n",
            "52/52 [==============================] - 0s 906us/step - loss: 1.8408 - accuracy: 0.2500\n",
            "Epoch 501/2000\n",
            "52/52 [==============================] - 0s 944us/step - loss: 1.8410 - accuracy: 0.2500\n",
            "Epoch 502/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8405 - accuracy: 0.2692\n",
            "Epoch 503/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8402 - accuracy: 0.2500\n",
            "Epoch 504/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8403 - accuracy: 0.2692\n",
            "Epoch 505/2000\n",
            "52/52 [==============================] - 0s 987us/step - loss: 1.8405 - accuracy: 0.2692\n",
            "Epoch 506/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8396 - accuracy: 0.2692\n",
            "Epoch 507/2000\n",
            "52/52 [==============================] - 0s 865us/step - loss: 1.8399 - accuracy: 0.2692\n",
            "Epoch 508/2000\n",
            "52/52 [==============================] - 0s 918us/step - loss: 1.8402 - accuracy: 0.2500\n",
            "Epoch 509/2000\n",
            "52/52 [==============================] - 0s 922us/step - loss: 1.8398 - accuracy: 0.2500\n",
            "Epoch 510/2000\n",
            "52/52 [==============================] - 0s 828us/step - loss: 1.8401 - accuracy: 0.2692\n",
            "Epoch 511/2000\n",
            "52/52 [==============================] - 0s 836us/step - loss: 1.8400 - accuracy: 0.2500\n",
            "Epoch 512/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8408 - accuracy: 0.2500\n",
            "Epoch 513/2000\n",
            "52/52 [==============================] - 0s 871us/step - loss: 1.8402 - accuracy: 0.2692\n",
            "Epoch 514/2000\n",
            "52/52 [==============================] - 0s 930us/step - loss: 1.8406 - accuracy: 0.2692\n",
            "Epoch 515/2000\n",
            "52/52 [==============================] - 0s 865us/step - loss: 1.8406 - accuracy: 0.2500\n",
            "Epoch 516/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8405 - accuracy: 0.2500\n",
            "Epoch 517/2000\n",
            "52/52 [==============================] - 0s 895us/step - loss: 1.8400 - accuracy: 0.2692\n",
            "Epoch 518/2000\n",
            "52/52 [==============================] - 0s 923us/step - loss: 1.8410 - accuracy: 0.2500\n",
            "Epoch 519/2000\n",
            "52/52 [==============================] - 0s 931us/step - loss: 1.8415 - accuracy: 0.2500\n",
            "Epoch 520/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8423 - accuracy: 0.2500\n",
            "Epoch 521/2000\n",
            "52/52 [==============================] - 0s 943us/step - loss: 1.8415 - accuracy: 0.2500\n",
            "Epoch 522/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8415 - accuracy: 0.2500\n",
            "Epoch 523/2000\n",
            "52/52 [==============================] - 0s 850us/step - loss: 1.8411 - accuracy: 0.2500\n",
            "Epoch 524/2000\n",
            "52/52 [==============================] - 0s 923us/step - loss: 1.8411 - accuracy: 0.2692\n",
            "Epoch 525/2000\n",
            "52/52 [==============================] - 0s 865us/step - loss: 1.8417 - accuracy: 0.2500\n",
            "Epoch 526/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8417 - accuracy: 0.2500\n",
            "Epoch 527/2000\n",
            "52/52 [==============================] - 0s 833us/step - loss: 1.8407 - accuracy: 0.2500\n",
            "Epoch 528/2000\n",
            "52/52 [==============================] - 0s 782us/step - loss: 1.8405 - accuracy: 0.2500\n",
            "Epoch 529/2000\n",
            "52/52 [==============================] - 0s 930us/step - loss: 1.8419 - accuracy: 0.2500\n",
            "Epoch 530/2000\n",
            "52/52 [==============================] - 0s 854us/step - loss: 1.8410 - accuracy: 0.2692\n",
            "Epoch 531/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8410 - accuracy: 0.2692\n",
            "Epoch 532/2000\n",
            "52/52 [==============================] - 0s 898us/step - loss: 1.8414 - accuracy: 0.2692\n",
            "Epoch 533/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8421 - accuracy: 0.2308\n",
            "Epoch 534/2000\n",
            "52/52 [==============================] - 0s 937us/step - loss: 1.8420 - accuracy: 0.2500\n",
            "Epoch 535/2000\n",
            "52/52 [==============================] - 0s 831us/step - loss: 1.8404 - accuracy: 0.2500\n",
            "Epoch 536/2000\n",
            "52/52 [==============================] - 0s 918us/step - loss: 1.8418 - accuracy: 0.2500\n",
            "Epoch 537/2000\n",
            "52/52 [==============================] - 0s 831us/step - loss: 1.8412 - accuracy: 0.2308\n",
            "Epoch 538/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8405 - accuracy: 0.2500\n",
            "Epoch 539/2000\n",
            "52/52 [==============================] - 0s 870us/step - loss: 1.8417 - accuracy: 0.2500\n",
            "Epoch 540/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8406 - accuracy: 0.2500\n",
            "Epoch 541/2000\n",
            "52/52 [==============================] - 0s 948us/step - loss: 1.8419 - accuracy: 0.2500\n",
            "Epoch 542/2000\n",
            "52/52 [==============================] - 0s 998us/step - loss: 1.8407 - accuracy: 0.2500\n",
            "Epoch 543/2000\n",
            "52/52 [==============================] - 0s 851us/step - loss: 1.8415 - accuracy: 0.2308\n",
            "Epoch 544/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8403 - accuracy: 0.2500\n",
            "Epoch 545/2000\n",
            "52/52 [==============================] - 0s 853us/step - loss: 1.8405 - accuracy: 0.2308\n",
            "Epoch 546/2000\n",
            "52/52 [==============================] - 0s 815us/step - loss: 1.8400 - accuracy: 0.2308\n",
            "Epoch 547/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8408 - accuracy: 0.2500\n",
            "Epoch 548/2000\n",
            "52/52 [==============================] - 0s 932us/step - loss: 1.8400 - accuracy: 0.2692\n",
            "Epoch 549/2000\n",
            "52/52 [==============================] - 0s 868us/step - loss: 1.8409 - accuracy: 0.2500\n",
            "Epoch 550/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8398 - accuracy: 0.2692\n",
            "Epoch 551/2000\n",
            "52/52 [==============================] - 0s 863us/step - loss: 1.8409 - accuracy: 0.2692\n",
            "Epoch 552/2000\n",
            "52/52 [==============================] - 0s 984us/step - loss: 1.8408 - accuracy: 0.2692\n",
            "Epoch 553/2000\n",
            "52/52 [==============================] - 0s 823us/step - loss: 1.8406 - accuracy: 0.2500\n",
            "Epoch 554/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8417 - accuracy: 0.2500\n",
            "Epoch 555/2000\n",
            "52/52 [==============================] - 0s 836us/step - loss: 1.8413 - accuracy: 0.2500\n",
            "Epoch 556/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8405 - accuracy: 0.2692\n",
            "Epoch 557/2000\n",
            "52/52 [==============================] - 0s 837us/step - loss: 1.8400 - accuracy: 0.2500\n",
            "Epoch 558/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8406 - accuracy: 0.2500\n",
            "Epoch 559/2000\n",
            "52/52 [==============================] - 0s 886us/step - loss: 1.8411 - accuracy: 0.2692\n",
            "Epoch 560/2000\n",
            "52/52 [==============================] - 0s 994us/step - loss: 1.8400 - accuracy: 0.2500\n",
            "Epoch 561/2000\n",
            "52/52 [==============================] - 0s 874us/step - loss: 1.8411 - accuracy: 0.2692\n",
            "Epoch 562/2000\n",
            "52/52 [==============================] - 0s 904us/step - loss: 1.8417 - accuracy: 0.2692\n",
            "Epoch 563/2000\n",
            "52/52 [==============================] - 0s 859us/step - loss: 1.8407 - accuracy: 0.2500\n",
            "Epoch 564/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8409 - accuracy: 0.2500\n",
            "Epoch 565/2000\n",
            "52/52 [==============================] - 0s 838us/step - loss: 1.8401 - accuracy: 0.2692\n",
            "Epoch 566/2000\n",
            "52/52 [==============================] - 0s 912us/step - loss: 1.8399 - accuracy: 0.2692\n",
            "Epoch 567/2000\n",
            "52/52 [==============================] - 0s 853us/step - loss: 1.8416 - accuracy: 0.2500\n",
            "Epoch 568/2000\n",
            "52/52 [==============================] - 0s 890us/step - loss: 1.8414 - accuracy: 0.2692\n",
            "Epoch 569/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8412 - accuracy: 0.2692\n",
            "Epoch 570/2000\n",
            "52/52 [==============================] - 0s 875us/step - loss: 1.8411 - accuracy: 0.2692\n",
            "Epoch 571/2000\n",
            "52/52 [==============================] - 0s 903us/step - loss: 1.8405 - accuracy: 0.2500\n",
            "Epoch 572/2000\n",
            "52/52 [==============================] - 0s 949us/step - loss: 1.8402 - accuracy: 0.2692\n",
            "Epoch 573/2000\n",
            "52/52 [==============================] - 0s 915us/step - loss: 1.8406 - accuracy: 0.2692\n",
            "Epoch 574/2000\n",
            "52/52 [==============================] - 0s 953us/step - loss: 1.8407 - accuracy: 0.2692\n",
            "Epoch 575/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8406 - accuracy: 0.2692\n",
            "Epoch 576/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8406 - accuracy: 0.2500\n",
            "Epoch 577/2000\n",
            "52/52 [==============================] - 0s 894us/step - loss: 1.8404 - accuracy: 0.2692\n",
            "Epoch 578/2000\n",
            "52/52 [==============================] - 0s 875us/step - loss: 1.8407 - accuracy: 0.2692\n",
            "Epoch 579/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8405 - accuracy: 0.2692\n",
            "Epoch 580/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8407 - accuracy: 0.2500\n",
            "Epoch 581/2000\n",
            "52/52 [==============================] - 0s 816us/step - loss: 1.8402 - accuracy: 0.2692\n",
            "Epoch 582/2000\n",
            "52/52 [==============================] - 0s 903us/step - loss: 1.8404 - accuracy: 0.2500\n",
            "Epoch 583/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8414 - accuracy: 0.2692\n",
            "Epoch 584/2000\n",
            "52/52 [==============================] - 0s 848us/step - loss: 1.8409 - accuracy: 0.2692\n",
            "Epoch 585/2000\n",
            "52/52 [==============================] - 0s 995us/step - loss: 1.8409 - accuracy: 0.2500\n",
            "Epoch 586/2000\n",
            "52/52 [==============================] - 0s 921us/step - loss: 1.8403 - accuracy: 0.2500\n",
            "Epoch 587/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8406 - accuracy: 0.2692\n",
            "Epoch 588/2000\n",
            "52/52 [==============================] - 0s 873us/step - loss: 1.8405 - accuracy: 0.2692\n",
            "Epoch 589/2000\n",
            "52/52 [==============================] - 0s 894us/step - loss: 1.8418 - accuracy: 0.2692\n",
            "Epoch 590/2000\n",
            "52/52 [==============================] - 0s 916us/step - loss: 1.8401 - accuracy: 0.2500\n",
            "Epoch 591/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8403 - accuracy: 0.2692\n",
            "Epoch 592/2000\n",
            "52/52 [==============================] - 0s 931us/step - loss: 1.8412 - accuracy: 0.2308\n",
            "Epoch 593/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8408 - accuracy: 0.2692\n",
            "Epoch 594/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8411 - accuracy: 0.2500\n",
            "Epoch 595/2000\n",
            "52/52 [==============================] - 0s 955us/step - loss: 1.8421 - accuracy: 0.2692\n",
            "Epoch 596/2000\n",
            "52/52 [==============================] - 0s 892us/step - loss: 1.8421 - accuracy: 0.2500\n",
            "Epoch 597/2000\n",
            "52/52 [==============================] - 0s 861us/step - loss: 1.8422 - accuracy: 0.2500\n",
            "Epoch 598/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8418 - accuracy: 0.2692\n",
            "Epoch 599/2000\n",
            "52/52 [==============================] - 0s 797us/step - loss: 1.8411 - accuracy: 0.2500\n",
            "Epoch 600/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8422 - accuracy: 0.2500\n",
            "Epoch 601/2000\n",
            "52/52 [==============================] - 0s 949us/step - loss: 1.8417 - accuracy: 0.2692\n",
            "Epoch 602/2000\n",
            "52/52 [==============================] - 0s 763us/step - loss: 1.8424 - accuracy: 0.2692\n",
            "Epoch 603/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8431 - accuracy: 0.2500\n",
            "Epoch 604/2000\n",
            "52/52 [==============================] - 0s 906us/step - loss: 1.8433 - accuracy: 0.2500\n",
            "Epoch 605/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8427 - accuracy: 0.2692\n",
            "Epoch 606/2000\n",
            "52/52 [==============================] - 0s 851us/step - loss: 1.8427 - accuracy: 0.2692\n",
            "Epoch 607/2000\n",
            "52/52 [==============================] - 0s 915us/step - loss: 1.8437 - accuracy: 0.2500\n",
            "Epoch 608/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8430 - accuracy: 0.2500\n",
            "Epoch 609/2000\n",
            "52/52 [==============================] - 0s 866us/step - loss: 1.8440 - accuracy: 0.2500\n",
            "Epoch 610/2000\n",
            "52/52 [==============================] - 0s 985us/step - loss: 1.8437 - accuracy: 0.2692\n",
            "Epoch 611/2000\n",
            "52/52 [==============================] - 0s 896us/step - loss: 1.8439 - accuracy: 0.2692\n",
            "Epoch 612/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8439 - accuracy: 0.2692\n",
            "Epoch 613/2000\n",
            "52/52 [==============================] - 0s 899us/step - loss: 1.8432 - accuracy: 0.2692\n",
            "Epoch 614/2000\n",
            "52/52 [==============================] - 0s 948us/step - loss: 1.8433 - accuracy: 0.2885\n",
            "Epoch 615/2000\n",
            "52/52 [==============================] - 0s 907us/step - loss: 1.8423 - accuracy: 0.2692\n",
            "Epoch 616/2000\n",
            "52/52 [==============================] - 0s 947us/step - loss: 1.8415 - accuracy: 0.2885\n",
            "Epoch 617/2000\n",
            "52/52 [==============================] - 0s 912us/step - loss: 1.8419 - accuracy: 0.2885\n",
            "Epoch 618/2000\n",
            "52/52 [==============================] - 0s 914us/step - loss: 1.8421 - accuracy: 0.2885\n",
            "Epoch 619/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8433 - accuracy: 0.2692\n",
            "Epoch 620/2000\n",
            "52/52 [==============================] - 0s 956us/step - loss: 1.8421 - accuracy: 0.2885\n",
            "Epoch 621/2000\n",
            "52/52 [==============================] - 0s 866us/step - loss: 1.8417 - accuracy: 0.2692\n",
            "Epoch 622/2000\n",
            "52/52 [==============================] - 0s 953us/step - loss: 1.8421 - accuracy: 0.2692\n",
            "Epoch 623/2000\n",
            "52/52 [==============================] - 0s 939us/step - loss: 1.8407 - accuracy: 0.2692\n",
            "Epoch 624/2000\n",
            "52/52 [==============================] - 0s 987us/step - loss: 1.8423 - accuracy: 0.2692\n",
            "Epoch 625/2000\n",
            "52/52 [==============================] - 0s 937us/step - loss: 1.8423 - accuracy: 0.2885\n",
            "Epoch 626/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8404 - accuracy: 0.2885\n",
            "Epoch 627/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8415 - accuracy: 0.2885\n",
            "Epoch 628/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8404 - accuracy: 0.2692\n",
            "Epoch 629/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8408 - accuracy: 0.2692\n",
            "Epoch 630/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8404 - accuracy: 0.2692\n",
            "Epoch 631/2000\n",
            "52/52 [==============================] - 0s 858us/step - loss: 1.8409 - accuracy: 0.2885\n",
            "Epoch 632/2000\n",
            "52/52 [==============================] - 0s 829us/step - loss: 1.8405 - accuracy: 0.2500\n",
            "Epoch 633/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8415 - accuracy: 0.2692\n",
            "Epoch 634/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8408 - accuracy: 0.2500\n",
            "Epoch 635/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8407 - accuracy: 0.2500\n",
            "Epoch 636/2000\n",
            "52/52 [==============================] - 0s 852us/step - loss: 1.8393 - accuracy: 0.2885\n",
            "Epoch 637/2000\n",
            "52/52 [==============================] - 0s 869us/step - loss: 1.8393 - accuracy: 0.2692\n",
            "Epoch 638/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8411 - accuracy: 0.2692\n",
            "Epoch 639/2000\n",
            "52/52 [==============================] - 0s 922us/step - loss: 1.8407 - accuracy: 0.2885\n",
            "Epoch 640/2000\n",
            "52/52 [==============================] - 0s 858us/step - loss: 1.8403 - accuracy: 0.2885\n",
            "Epoch 641/2000\n",
            "52/52 [==============================] - 0s 916us/step - loss: 1.8400 - accuracy: 0.2692\n",
            "Epoch 642/2000\n",
            "52/52 [==============================] - 0s 910us/step - loss: 1.8408 - accuracy: 0.2692\n",
            "Epoch 643/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8401 - accuracy: 0.2692\n",
            "Epoch 644/2000\n",
            "52/52 [==============================] - 0s 947us/step - loss: 1.8394 - accuracy: 0.2500\n",
            "Epoch 645/2000\n",
            "52/52 [==============================] - 0s 922us/step - loss: 1.8407 - accuracy: 0.2500\n",
            "Epoch 646/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8398 - accuracy: 0.2500\n",
            "Epoch 647/2000\n",
            "52/52 [==============================] - 0s 957us/step - loss: 1.8401 - accuracy: 0.2692\n",
            "Epoch 648/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8397 - accuracy: 0.2500\n",
            "Epoch 649/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8396 - accuracy: 0.2500\n",
            "Epoch 650/2000\n",
            "52/52 [==============================] - 0s 831us/step - loss: 1.8393 - accuracy: 0.2500\n",
            "Epoch 651/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8396 - accuracy: 0.2500\n",
            "Epoch 652/2000\n",
            "52/52 [==============================] - 0s 862us/step - loss: 1.8397 - accuracy: 0.2692\n",
            "Epoch 653/2000\n",
            "52/52 [==============================] - 0s 907us/step - loss: 1.8391 - accuracy: 0.2500\n",
            "Epoch 654/2000\n",
            "52/52 [==============================] - 0s 923us/step - loss: 1.8399 - accuracy: 0.2692\n",
            "Epoch 655/2000\n",
            "52/52 [==============================] - 0s 928us/step - loss: 1.8392 - accuracy: 0.2500\n",
            "Epoch 656/2000\n",
            "52/52 [==============================] - 0s 914us/step - loss: 1.8393 - accuracy: 0.2500\n",
            "Epoch 657/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8397 - accuracy: 0.2500\n",
            "Epoch 658/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8391 - accuracy: 0.2500\n",
            "Epoch 659/2000\n",
            "52/52 [==============================] - 0s 866us/step - loss: 1.8399 - accuracy: 0.2500\n",
            "Epoch 660/2000\n",
            "52/52 [==============================] - 0s 911us/step - loss: 1.8401 - accuracy: 0.2692\n",
            "Epoch 661/2000\n",
            "52/52 [==============================] - 0s 963us/step - loss: 1.8387 - accuracy: 0.2692\n",
            "Epoch 662/2000\n",
            "52/52 [==============================] - 0s 866us/step - loss: 1.8400 - accuracy: 0.2692\n",
            "Epoch 663/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8388 - accuracy: 0.2500\n",
            "Epoch 664/2000\n",
            "52/52 [==============================] - 0s 914us/step - loss: 1.8399 - accuracy: 0.2500\n",
            "Epoch 665/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8386 - accuracy: 0.2500\n",
            "Epoch 666/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8387 - accuracy: 0.2885\n",
            "Epoch 667/2000\n",
            "52/52 [==============================] - 0s 894us/step - loss: 1.8412 - accuracy: 0.2692\n",
            "Epoch 668/2000\n",
            "52/52 [==============================] - 0s 927us/step - loss: 1.8400 - accuracy: 0.2885\n",
            "Epoch 669/2000\n",
            "52/52 [==============================] - 0s 921us/step - loss: 1.8391 - accuracy: 0.2692\n",
            "Epoch 670/2000\n",
            "52/52 [==============================] - 0s 924us/step - loss: 1.8390 - accuracy: 0.2692\n",
            "Epoch 671/2000\n",
            "52/52 [==============================] - 0s 892us/step - loss: 1.8385 - accuracy: 0.2692\n",
            "Epoch 672/2000\n",
            "52/52 [==============================] - 0s 961us/step - loss: 1.8384 - accuracy: 0.2692\n",
            "Epoch 673/2000\n",
            "52/52 [==============================] - 0s 859us/step - loss: 1.8381 - accuracy: 0.2692\n",
            "Epoch 674/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8386 - accuracy: 0.2692\n",
            "Epoch 675/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 676/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8389 - accuracy: 0.2692\n",
            "Epoch 677/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8377 - accuracy: 0.2885\n",
            "Epoch 678/2000\n",
            "52/52 [==============================] - 0s 904us/step - loss: 1.8387 - accuracy: 0.2692\n",
            "Epoch 679/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8375 - accuracy: 0.2885\n",
            "Epoch 680/2000\n",
            "52/52 [==============================] - 0s 925us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 681/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8377 - accuracy: 0.2885\n",
            "Epoch 682/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8381 - accuracy: 0.2692\n",
            "Epoch 683/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8369 - accuracy: 0.2885\n",
            "Epoch 684/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8374 - accuracy: 0.2885\n",
            "Epoch 685/2000\n",
            "52/52 [==============================] - 0s 950us/step - loss: 1.8375 - accuracy: 0.2885\n",
            "Epoch 686/2000\n",
            "52/52 [==============================] - 0s 920us/step - loss: 1.8369 - accuracy: 0.2692\n",
            "Epoch 687/2000\n",
            "52/52 [==============================] - 0s 922us/step - loss: 1.8372 - accuracy: 0.2692\n",
            "Epoch 688/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8370 - accuracy: 0.2692\n",
            "Epoch 689/2000\n",
            "52/52 [==============================] - 0s 893us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 690/2000\n",
            "52/52 [==============================] - 0s 895us/step - loss: 1.8376 - accuracy: 0.2692\n",
            "Epoch 691/2000\n",
            "52/52 [==============================] - 0s 818us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 692/2000\n",
            "52/52 [==============================] - 0s 879us/step - loss: 1.8381 - accuracy: 0.2692\n",
            "Epoch 693/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8373 - accuracy: 0.2885\n",
            "Epoch 694/2000\n",
            "52/52 [==============================] - 0s 904us/step - loss: 1.8380 - accuracy: 0.2885\n",
            "Epoch 695/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 696/2000\n",
            "52/52 [==============================] - 0s 890us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 697/2000\n",
            "52/52 [==============================] - 0s 906us/step - loss: 1.8377 - accuracy: 0.2692\n",
            "Epoch 698/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 699/2000\n",
            "52/52 [==============================] - 0s 895us/step - loss: 1.8366 - accuracy: 0.2692\n",
            "Epoch 700/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8376 - accuracy: 0.2692\n",
            "Epoch 701/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8372 - accuracy: 0.2885\n",
            "Epoch 702/2000\n",
            "52/52 [==============================] - 0s 883us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 703/2000\n",
            "52/52 [==============================] - 0s 886us/step - loss: 1.8366 - accuracy: 0.2692\n",
            "Epoch 704/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 705/2000\n",
            "52/52 [==============================] - 0s 927us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 706/2000\n",
            "52/52 [==============================] - 0s 909us/step - loss: 1.8355 - accuracy: 0.2692\n",
            "Epoch 707/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8370 - accuracy: 0.2692\n",
            "Epoch 708/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8365 - accuracy: 0.2692\n",
            "Epoch 709/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8361 - accuracy: 0.2692\n",
            "Epoch 710/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8367 - accuracy: 0.2692\n",
            "Epoch 711/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8363 - accuracy: 0.2692\n",
            "Epoch 712/2000\n",
            "52/52 [==============================] - 0s 910us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 713/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8364 - accuracy: 0.2692\n",
            "Epoch 714/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8369 - accuracy: 0.2692\n",
            "Epoch 715/2000\n",
            "52/52 [==============================] - 0s 902us/step - loss: 1.8359 - accuracy: 0.2692\n",
            "Epoch 716/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8367 - accuracy: 0.2692\n",
            "Epoch 717/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 718/2000\n",
            "52/52 [==============================] - 0s 906us/step - loss: 1.8370 - accuracy: 0.2885\n",
            "Epoch 719/2000\n",
            "52/52 [==============================] - 0s 881us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 720/2000\n",
            "52/52 [==============================] - 0s 898us/step - loss: 1.8362 - accuracy: 0.2692\n",
            "Epoch 721/2000\n",
            "52/52 [==============================] - 0s 960us/step - loss: 1.8365 - accuracy: 0.2885\n",
            "Epoch 722/2000\n",
            "52/52 [==============================] - 0s 922us/step - loss: 1.8363 - accuracy: 0.2692\n",
            "Epoch 723/2000\n",
            "52/52 [==============================] - 0s 889us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 724/2000\n",
            "52/52 [==============================] - 0s 875us/step - loss: 1.8370 - accuracy: 0.2692\n",
            "Epoch 725/2000\n",
            "52/52 [==============================] - 0s 941us/step - loss: 1.8373 - accuracy: 0.2692\n",
            "Epoch 726/2000\n",
            "52/52 [==============================] - 0s 912us/step - loss: 1.8358 - accuracy: 0.2692\n",
            "Epoch 727/2000\n",
            "52/52 [==============================] - 0s 921us/step - loss: 1.8371 - accuracy: 0.2692\n",
            "Epoch 728/2000\n",
            "52/52 [==============================] - 0s 913us/step - loss: 1.8357 - accuracy: 0.2692\n",
            "Epoch 729/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8355 - accuracy: 0.2692\n",
            "Epoch 730/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8352 - accuracy: 0.2692\n",
            "Epoch 731/2000\n",
            "52/52 [==============================] - 0s 917us/step - loss: 1.8362 - accuracy: 0.2692\n",
            "Epoch 732/2000\n",
            "52/52 [==============================] - 0s 915us/step - loss: 1.8361 - accuracy: 0.2692\n",
            "Epoch 733/2000\n",
            "52/52 [==============================] - 0s 920us/step - loss: 1.8359 - accuracy: 0.2692\n",
            "Epoch 734/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8364 - accuracy: 0.2692\n",
            "Epoch 735/2000\n",
            "52/52 [==============================] - 0s 992us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 736/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8367 - accuracy: 0.2692\n",
            "Epoch 737/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8367 - accuracy: 0.2692\n",
            "Epoch 738/2000\n",
            "52/52 [==============================] - 0s 848us/step - loss: 1.8366 - accuracy: 0.2692\n",
            "Epoch 739/2000\n",
            "52/52 [==============================] - 0s 998us/step - loss: 1.8371 - accuracy: 0.2692\n",
            "Epoch 740/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8381 - accuracy: 0.2692\n",
            "Epoch 741/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8358 - accuracy: 0.2692\n",
            "Epoch 742/2000\n",
            "52/52 [==============================] - 0s 952us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 743/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8377 - accuracy: 0.2692\n",
            "Epoch 744/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8371 - accuracy: 0.2692\n",
            "Epoch 745/2000\n",
            "52/52 [==============================] - 0s 884us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 746/2000\n",
            "52/52 [==============================] - 0s 950us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 747/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8371 - accuracy: 0.2692\n",
            "Epoch 748/2000\n",
            "52/52 [==============================] - 0s 853us/step - loss: 1.8379 - accuracy: 0.2692\n",
            "Epoch 749/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8369 - accuracy: 0.2692\n",
            "Epoch 750/2000\n",
            "52/52 [==============================] - 0s 877us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 751/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8385 - accuracy: 0.2692\n",
            "Epoch 752/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8376 - accuracy: 0.2692\n",
            "Epoch 753/2000\n",
            "52/52 [==============================] - 0s 881us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 754/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8381 - accuracy: 0.2692\n",
            "Epoch 755/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8370 - accuracy: 0.2692\n",
            "Epoch 756/2000\n",
            "52/52 [==============================] - 0s 938us/step - loss: 1.8368 - accuracy: 0.2692\n",
            "Epoch 757/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8365 - accuracy: 0.2692\n",
            "Epoch 758/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8367 - accuracy: 0.2692\n",
            "Epoch 759/2000\n",
            "52/52 [==============================] - 0s 903us/step - loss: 1.8363 - accuracy: 0.2692\n",
            "Epoch 760/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8378 - accuracy: 0.2692\n",
            "Epoch 761/2000\n",
            "52/52 [==============================] - 0s 856us/step - loss: 1.8383 - accuracy: 0.2692\n",
            "Epoch 762/2000\n",
            "52/52 [==============================] - 0s 900us/step - loss: 1.8384 - accuracy: 0.2692\n",
            "Epoch 763/2000\n",
            "52/52 [==============================] - 0s 926us/step - loss: 1.8375 - accuracy: 0.2692\n",
            "Epoch 764/2000\n",
            "52/52 [==============================] - 0s 887us/step - loss: 1.8376 - accuracy: 0.2692\n",
            "Epoch 765/2000\n",
            "52/52 [==============================] - 0s 936us/step - loss: 1.8364 - accuracy: 0.2692\n",
            "Epoch 766/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 767/2000\n",
            "52/52 [==============================] - 0s 917us/step - loss: 1.8381 - accuracy: 0.2885\n",
            "Epoch 768/2000\n",
            "52/52 [==============================] - 0s 865us/step - loss: 1.8374 - accuracy: 0.2692\n",
            "Epoch 769/2000\n",
            "52/52 [==============================] - 0s 955us/step - loss: 1.8366 - accuracy: 0.2692\n",
            "Epoch 770/2000\n",
            "52/52 [==============================] - 0s 944us/step - loss: 1.8374 - accuracy: 0.2885\n",
            "Epoch 771/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8367 - accuracy: 0.2692\n",
            "Epoch 772/2000\n",
            "52/52 [==============================] - 0s 886us/step - loss: 1.8360 - accuracy: 0.2692\n",
            "Epoch 773/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8357 - accuracy: 0.2692\n",
            "Epoch 774/2000\n",
            "52/52 [==============================] - 0s 841us/step - loss: 1.8360 - accuracy: 0.2692\n",
            "Epoch 775/2000\n",
            "52/52 [==============================] - 0s 955us/step - loss: 1.8379 - accuracy: 0.2692\n",
            "Epoch 776/2000\n",
            "52/52 [==============================] - 0s 944us/step - loss: 1.8364 - accuracy: 0.2692\n",
            "Epoch 777/2000\n",
            "52/52 [==============================] - 0s 939us/step - loss: 1.8365 - accuracy: 0.2692\n",
            "Epoch 778/2000\n",
            "52/52 [==============================] - 0s 956us/step - loss: 1.8359 - accuracy: 0.2692\n",
            "Epoch 779/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8359 - accuracy: 0.2692\n",
            "Epoch 780/2000\n",
            "52/52 [==============================] - 0s 949us/step - loss: 1.8369 - accuracy: 0.2500\n",
            "Epoch 781/2000\n",
            "52/52 [==============================] - 0s 950us/step - loss: 1.8357 - accuracy: 0.2692\n",
            "Epoch 782/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8353 - accuracy: 0.2692\n",
            "Epoch 783/2000\n",
            "52/52 [==============================] - 0s 960us/step - loss: 1.8342 - accuracy: 0.2692\n",
            "Epoch 784/2000\n",
            "52/52 [==============================] - 0s 956us/step - loss: 1.8353 - accuracy: 0.2692\n",
            "Epoch 785/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8353 - accuracy: 0.2692\n",
            "Epoch 786/2000\n",
            "52/52 [==============================] - 0s 944us/step - loss: 1.8361 - accuracy: 0.2500\n",
            "Epoch 787/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8352 - accuracy: 0.2692\n",
            "Epoch 788/2000\n",
            "52/52 [==============================] - 0s 944us/step - loss: 1.8347 - accuracy: 0.2692\n",
            "Epoch 789/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8346 - accuracy: 0.2692\n",
            "Epoch 790/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8337 - accuracy: 0.2500\n",
            "Epoch 791/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8336 - accuracy: 0.2692\n",
            "Epoch 792/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8354 - accuracy: 0.2692\n",
            "Epoch 793/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8351 - accuracy: 0.2500\n",
            "Epoch 794/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8344 - accuracy: 0.2500\n",
            "Epoch 795/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8344 - accuracy: 0.2692\n",
            "Epoch 796/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8325 - accuracy: 0.2500\n",
            "Epoch 797/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8344 - accuracy: 0.2500\n",
            "Epoch 798/2000\n",
            "52/52 [==============================] - 0s 944us/step - loss: 1.8334 - accuracy: 0.2885\n",
            "Epoch 799/2000\n",
            "52/52 [==============================] - 0s 959us/step - loss: 1.8334 - accuracy: 0.2500\n",
            "Epoch 800/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8342 - accuracy: 0.2692\n",
            "Epoch 801/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8329 - accuracy: 0.2692\n",
            "Epoch 802/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8335 - accuracy: 0.2692\n",
            "Epoch 803/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8330 - accuracy: 0.2692\n",
            "Epoch 804/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8356 - accuracy: 0.2500\n",
            "Epoch 805/2000\n",
            "52/52 [==============================] - 0s 954us/step - loss: 1.8342 - accuracy: 0.2692\n",
            "Epoch 806/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8345 - accuracy: 0.2692\n",
            "Epoch 807/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8333 - accuracy: 0.2692\n",
            "Epoch 808/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8335 - accuracy: 0.2692\n",
            "Epoch 809/2000\n",
            "52/52 [==============================] - 0s 989us/step - loss: 1.8324 - accuracy: 0.2692\n",
            "Epoch 810/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8332 - accuracy: 0.2692\n",
            "Epoch 811/2000\n",
            "52/52 [==============================] - 0s 948us/step - loss: 1.8332 - accuracy: 0.2885\n",
            "Epoch 812/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8329 - accuracy: 0.2692\n",
            "Epoch 813/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8330 - accuracy: 0.2692\n",
            "Epoch 814/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8342 - accuracy: 0.2692\n",
            "Epoch 815/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8319 - accuracy: 0.2692\n",
            "Epoch 816/2000\n",
            "52/52 [==============================] - 0s 952us/step - loss: 1.8333 - accuracy: 0.2692\n",
            "Epoch 817/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8329 - accuracy: 0.2692\n",
            "Epoch 818/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8331 - accuracy: 0.2692\n",
            "Epoch 819/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8316 - accuracy: 0.2692\n",
            "Epoch 820/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8321 - accuracy: 0.2692\n",
            "Epoch 821/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8311 - accuracy: 0.2692\n",
            "Epoch 822/2000\n",
            "52/52 [==============================] - 0s 941us/step - loss: 1.8315 - accuracy: 0.2692\n",
            "Epoch 823/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8313 - accuracy: 0.2692\n",
            "Epoch 824/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8312 - accuracy: 0.2692\n",
            "Epoch 825/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8307 - accuracy: 0.2692\n",
            "Epoch 826/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8322 - accuracy: 0.2692\n",
            "Epoch 827/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8320 - accuracy: 0.2692\n",
            "Epoch 828/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8314 - accuracy: 0.2692\n",
            "Epoch 829/2000\n",
            "52/52 [==============================] - 0s 897us/step - loss: 1.8313 - accuracy: 0.2692\n",
            "Epoch 830/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8308 - accuracy: 0.2692\n",
            "Epoch 831/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8306 - accuracy: 0.2692\n",
            "Epoch 832/2000\n",
            "52/52 [==============================] - 0s 943us/step - loss: 1.8310 - accuracy: 0.2692\n",
            "Epoch 833/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8296 - accuracy: 0.2692\n",
            "Epoch 834/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8305 - accuracy: 0.2692\n",
            "Epoch 835/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8301 - accuracy: 0.2692\n",
            "Epoch 836/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8309 - accuracy: 0.2692\n",
            "Epoch 837/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8299 - accuracy: 0.2692\n",
            "Epoch 838/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8297 - accuracy: 0.2500\n",
            "Epoch 839/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8291 - accuracy: 0.2692\n",
            "Epoch 840/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8295 - accuracy: 0.2692\n",
            "Epoch 841/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8291 - accuracy: 0.2692\n",
            "Epoch 842/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8295 - accuracy: 0.2692\n",
            "Epoch 843/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8296 - accuracy: 0.2692\n",
            "Epoch 844/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8297 - accuracy: 0.2692\n",
            "Epoch 845/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8299 - accuracy: 0.2692\n",
            "Epoch 846/2000\n",
            "52/52 [==============================] - 0s 947us/step - loss: 1.8301 - accuracy: 0.2692\n",
            "Epoch 847/2000\n",
            "52/52 [==============================] - 0s 950us/step - loss: 1.8292 - accuracy: 0.2692\n",
            "Epoch 848/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8303 - accuracy: 0.2500\n",
            "Epoch 849/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8296 - accuracy: 0.2692\n",
            "Epoch 850/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8303 - accuracy: 0.2692\n",
            "Epoch 851/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8311 - accuracy: 0.2500\n",
            "Epoch 852/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8303 - accuracy: 0.2500\n",
            "Epoch 853/2000\n",
            "52/52 [==============================] - 0s 964us/step - loss: 1.8295 - accuracy: 0.2500\n",
            "Epoch 854/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8296 - accuracy: 0.2692\n",
            "Epoch 855/2000\n",
            "52/52 [==============================] - 0s 950us/step - loss: 1.8290 - accuracy: 0.2500\n",
            "Epoch 856/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8308 - accuracy: 0.2500\n",
            "Epoch 857/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8293 - accuracy: 0.2692\n",
            "Epoch 858/2000\n",
            "52/52 [==============================] - 0s 952us/step - loss: 1.8289 - accuracy: 0.2692\n",
            "Epoch 859/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8283 - accuracy: 0.2692\n",
            "Epoch 860/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8296 - accuracy: 0.2692\n",
            "Epoch 861/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8297 - accuracy: 0.2692\n",
            "Epoch 862/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8295 - accuracy: 0.2692\n",
            "Epoch 863/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8295 - accuracy: 0.2500\n",
            "Epoch 864/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8299 - accuracy: 0.2500\n",
            "Epoch 865/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8290 - accuracy: 0.2692\n",
            "Epoch 866/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8294 - accuracy: 0.2692\n",
            "Epoch 867/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8293 - accuracy: 0.2692\n",
            "Epoch 868/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8284 - accuracy: 0.2692\n",
            "Epoch 869/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8289 - accuracy: 0.2692\n",
            "Epoch 870/2000\n",
            "52/52 [==============================] - 0s 952us/step - loss: 1.8286 - accuracy: 0.2500\n",
            "Epoch 871/2000\n",
            "52/52 [==============================] - 0s 932us/step - loss: 1.8287 - accuracy: 0.2500\n",
            "Epoch 872/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8293 - accuracy: 0.2692\n",
            "Epoch 873/2000\n",
            "52/52 [==============================] - 0s 961us/step - loss: 1.8284 - accuracy: 0.2692\n",
            "Epoch 874/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8272 - accuracy: 0.2692\n",
            "Epoch 875/2000\n",
            "52/52 [==============================] - 0s 998us/step - loss: 1.8270 - accuracy: 0.2692\n",
            "Epoch 876/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8283 - accuracy: 0.2692\n",
            "Epoch 877/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8273 - accuracy: 0.2692\n",
            "Epoch 878/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8278 - accuracy: 0.2500\n",
            "Epoch 879/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8266 - accuracy: 0.2692\n",
            "Epoch 880/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8276 - accuracy: 0.2692\n",
            "Epoch 881/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8272 - accuracy: 0.2692\n",
            "Epoch 882/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8279 - accuracy: 0.2692\n",
            "Epoch 883/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8262 - accuracy: 0.2692\n",
            "Epoch 884/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8271 - accuracy: 0.2692\n",
            "Epoch 885/2000\n",
            "52/52 [==============================] - 0s 989us/step - loss: 1.8274 - accuracy: 0.2692\n",
            "Epoch 886/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8270 - accuracy: 0.2692\n",
            "Epoch 887/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8278 - accuracy: 0.2885\n",
            "Epoch 888/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8279 - accuracy: 0.2692\n",
            "Epoch 889/2000\n",
            "52/52 [==============================] - 0s 902us/step - loss: 1.8261 - accuracy: 0.2692\n",
            "Epoch 890/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8272 - accuracy: 0.2692\n",
            "Epoch 891/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8248 - accuracy: 0.2692\n",
            "Epoch 892/2000\n",
            "52/52 [==============================] - 0s 954us/step - loss: 1.8263 - accuracy: 0.2692\n",
            "Epoch 893/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8270 - accuracy: 0.2692\n",
            "Epoch 894/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8263 - accuracy: 0.2692\n",
            "Epoch 895/2000\n",
            "52/52 [==============================] - 0s 992us/step - loss: 1.8270 - accuracy: 0.2692\n",
            "Epoch 896/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8250 - accuracy: 0.2692\n",
            "Epoch 897/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8267 - accuracy: 0.2692\n",
            "Epoch 898/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8248 - accuracy: 0.2692\n",
            "Epoch 899/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8249 - accuracy: 0.2692\n",
            "Epoch 900/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8246 - accuracy: 0.2692\n",
            "Epoch 901/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8245 - accuracy: 0.2692\n",
            "Epoch 902/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8239 - accuracy: 0.2692\n",
            "Epoch 903/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8232 - accuracy: 0.2692\n",
            "Epoch 904/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8235 - accuracy: 0.2692\n",
            "Epoch 905/2000\n",
            "52/52 [==============================] - 0s 915us/step - loss: 1.8258 - accuracy: 0.2692\n",
            "Epoch 906/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8241 - accuracy: 0.2692\n",
            "Epoch 907/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8244 - accuracy: 0.2500\n",
            "Epoch 908/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8251 - accuracy: 0.2692\n",
            "Epoch 909/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8255 - accuracy: 0.2692\n",
            "Epoch 910/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8244 - accuracy: 0.2692\n",
            "Epoch 911/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8249 - accuracy: 0.2692\n",
            "Epoch 912/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8242 - accuracy: 0.2692\n",
            "Epoch 913/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8243 - accuracy: 0.2692\n",
            "Epoch 914/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8243 - accuracy: 0.2692\n",
            "Epoch 915/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8229 - accuracy: 0.2692\n",
            "Epoch 916/2000\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8225 - accuracy: 0.2692\n",
            "Epoch 917/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8237 - accuracy: 0.2692\n",
            "Epoch 918/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8230 - accuracy: 0.2500\n",
            "Epoch 919/2000\n",
            "52/52 [==============================] - 0s 987us/step - loss: 1.8234 - accuracy: 0.2692\n",
            "Epoch 920/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8222 - accuracy: 0.2692\n",
            "Epoch 921/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8240 - accuracy: 0.2692\n",
            "Epoch 922/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8238 - accuracy: 0.2692\n",
            "Epoch 923/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8234 - accuracy: 0.2692\n",
            "Epoch 924/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8227 - accuracy: 0.2692\n",
            "Epoch 925/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8231 - accuracy: 0.2692\n",
            "Epoch 926/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8222 - accuracy: 0.2692\n",
            "Epoch 927/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8221 - accuracy: 0.2692\n",
            "Epoch 928/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8213 - accuracy: 0.2692\n",
            "Epoch 929/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8222 - accuracy: 0.2308\n",
            "Epoch 930/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8228 - accuracy: 0.2500\n",
            "Epoch 931/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8211 - accuracy: 0.2692\n",
            "Epoch 932/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8217 - accuracy: 0.2692\n",
            "Epoch 933/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8211 - accuracy: 0.2692\n",
            "Epoch 934/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8224 - accuracy: 0.2308\n",
            "Epoch 935/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8226 - accuracy: 0.2500\n",
            "Epoch 936/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8235 - accuracy: 0.2692\n",
            "Epoch 937/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8220 - accuracy: 0.2692\n",
            "Epoch 938/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8218 - accuracy: 0.2500\n",
            "Epoch 939/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8215 - accuracy: 0.2692\n",
            "Epoch 940/2000\n",
            "52/52 [==============================] - 0s 855us/step - loss: 1.8210 - accuracy: 0.2692\n",
            "Epoch 941/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8217 - accuracy: 0.2692\n",
            "Epoch 942/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8214 - accuracy: 0.2500\n",
            "Epoch 943/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8207 - accuracy: 0.2692\n",
            "Epoch 944/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8207 - accuracy: 0.2692\n",
            "Epoch 945/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8207 - accuracy: 0.2692\n",
            "Epoch 946/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8202 - accuracy: 0.2692\n",
            "Epoch 947/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8198 - accuracy: 0.2692\n",
            "Epoch 948/2000\n",
            "52/52 [==============================] - 0s 960us/step - loss: 1.8195 - accuracy: 0.2500\n",
            "Epoch 949/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8194 - accuracy: 0.2692\n",
            "Epoch 950/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8202 - accuracy: 0.2500\n",
            "Epoch 951/2000\n",
            "52/52 [==============================] - 0s 992us/step - loss: 1.8203 - accuracy: 0.2500\n",
            "Epoch 952/2000\n",
            "52/52 [==============================] - 0s 943us/step - loss: 1.8196 - accuracy: 0.2500\n",
            "Epoch 953/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8202 - accuracy: 0.2500\n",
            "Epoch 954/2000\n",
            "52/52 [==============================] - 0s 895us/step - loss: 1.8198 - accuracy: 0.2308\n",
            "Epoch 955/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8194 - accuracy: 0.2692\n",
            "Epoch 956/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8189 - accuracy: 0.2308\n",
            "Epoch 957/2000\n",
            "52/52 [==============================] - 0s 928us/step - loss: 1.8207 - accuracy: 0.2308\n",
            "Epoch 958/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8201 - accuracy: 0.2308\n",
            "Epoch 959/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8190 - accuracy: 0.2500\n",
            "Epoch 960/2000\n",
            "52/52 [==============================] - 0s 911us/step - loss: 1.8192 - accuracy: 0.2692\n",
            "Epoch 961/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8189 - accuracy: 0.2692\n",
            "Epoch 962/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8195 - accuracy: 0.2500\n",
            "Epoch 963/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8196 - accuracy: 0.2500\n",
            "Epoch 964/2000\n",
            "52/52 [==============================] - 0s 858us/step - loss: 1.8193 - accuracy: 0.2308\n",
            "Epoch 965/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8196 - accuracy: 0.2308\n",
            "Epoch 966/2000\n",
            "52/52 [==============================] - 0s 965us/step - loss: 1.8186 - accuracy: 0.2500\n",
            "Epoch 967/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8194 - accuracy: 0.2308\n",
            "Epoch 968/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8186 - accuracy: 0.2500\n",
            "Epoch 969/2000\n",
            "52/52 [==============================] - 0s 873us/step - loss: 1.8179 - accuracy: 0.2692\n",
            "Epoch 970/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8184 - accuracy: 0.2500\n",
            "Epoch 971/2000\n",
            "52/52 [==============================] - 0s 929us/step - loss: 1.8189 - accuracy: 0.2308\n",
            "Epoch 972/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8202 - accuracy: 0.2500\n",
            "Epoch 973/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8188 - accuracy: 0.2308\n",
            "Epoch 974/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8194 - accuracy: 0.2500\n",
            "Epoch 975/2000\n",
            "52/52 [==============================] - 0s 916us/step - loss: 1.8200 - accuracy: 0.2308\n",
            "Epoch 976/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8192 - accuracy: 0.2500\n",
            "Epoch 977/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8189 - accuracy: 0.2308\n",
            "Epoch 978/2000\n",
            "52/52 [==============================] - 0s 912us/step - loss: 1.8196 - accuracy: 0.2500\n",
            "Epoch 979/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8192 - accuracy: 0.2500\n",
            "Epoch 980/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8197 - accuracy: 0.2308\n",
            "Epoch 981/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8194 - accuracy: 0.2500\n",
            "Epoch 982/2000\n",
            "52/52 [==============================] - 0s 954us/step - loss: 1.8203 - accuracy: 0.2500\n",
            "Epoch 983/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8195 - accuracy: 0.2500\n",
            "Epoch 984/2000\n",
            "52/52 [==============================] - 0s 935us/step - loss: 1.8201 - accuracy: 0.2308\n",
            "Epoch 985/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8182 - accuracy: 0.2308\n",
            "Epoch 986/2000\n",
            "52/52 [==============================] - 0s 855us/step - loss: 1.8177 - accuracy: 0.2500\n",
            "Epoch 987/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8193 - accuracy: 0.2308\n",
            "Epoch 988/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8204 - accuracy: 0.2500\n",
            "Epoch 989/2000\n",
            "52/52 [==============================] - 0s 936us/step - loss: 1.8187 - accuracy: 0.2308\n",
            "Epoch 990/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8203 - accuracy: 0.2500\n",
            "Epoch 991/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8189 - accuracy: 0.2308\n",
            "Epoch 992/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8195 - accuracy: 0.2308\n",
            "Epoch 993/2000\n",
            "52/52 [==============================] - 0s 953us/step - loss: 1.8194 - accuracy: 0.2308\n",
            "Epoch 994/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8192 - accuracy: 0.2500\n",
            "Epoch 995/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8195 - accuracy: 0.2500\n",
            "Epoch 996/2000\n",
            "52/52 [==============================] - 0s 924us/step - loss: 1.8187 - accuracy: 0.2692\n",
            "Epoch 997/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8180 - accuracy: 0.2500\n",
            "Epoch 998/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8195 - accuracy: 0.2500\n",
            "Epoch 999/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8181 - accuracy: 0.2500\n",
            "Epoch 1000/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8178 - accuracy: 0.2308\n",
            "Epoch 1001/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8188 - accuracy: 0.2692\n",
            "Epoch 1002/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8183 - accuracy: 0.2692\n",
            "Epoch 1003/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8175 - accuracy: 0.2692\n",
            "Epoch 1004/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8184 - accuracy: 0.2692\n",
            "Epoch 1005/2000\n",
            "52/52 [==============================] - 0s 948us/step - loss: 1.8173 - accuracy: 0.2885\n",
            "Epoch 1006/2000\n",
            "52/52 [==============================] - 0s 891us/step - loss: 1.8174 - accuracy: 0.2885\n",
            "Epoch 1007/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8178 - accuracy: 0.2885\n",
            "Epoch 1008/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8171 - accuracy: 0.2692\n",
            "Epoch 1009/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8180 - accuracy: 0.2692\n",
            "Epoch 1010/2000\n",
            "52/52 [==============================] - 0s 916us/step - loss: 1.8185 - accuracy: 0.2692\n",
            "Epoch 1011/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8176 - accuracy: 0.2692\n",
            "Epoch 1012/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8172 - accuracy: 0.2692\n",
            "Epoch 1013/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8178 - accuracy: 0.2692\n",
            "Epoch 1014/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8176 - accuracy: 0.2692\n",
            "Epoch 1015/2000\n",
            "52/52 [==============================] - 0s 991us/step - loss: 1.8168 - accuracy: 0.2692\n",
            "Epoch 1016/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8184 - accuracy: 0.2692\n",
            "Epoch 1017/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8162 - accuracy: 0.2692\n",
            "Epoch 1018/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8156 - accuracy: 0.2692\n",
            "Epoch 1019/2000\n",
            "52/52 [==============================] - 0s 937us/step - loss: 1.8171 - accuracy: 0.2692\n",
            "Epoch 1020/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8156 - accuracy: 0.2692\n",
            "Epoch 1021/2000\n",
            "52/52 [==============================] - 0s 911us/step - loss: 1.8157 - accuracy: 0.2692\n",
            "Epoch 1022/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8147 - accuracy: 0.2692\n",
            "Epoch 1023/2000\n",
            "52/52 [==============================] - 0s 917us/step - loss: 1.8160 - accuracy: 0.2692\n",
            "Epoch 1024/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8147 - accuracy: 0.2692\n",
            "Epoch 1025/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8169 - accuracy: 0.2692\n",
            "Epoch 1026/2000\n",
            "52/52 [==============================] - 0s 961us/step - loss: 1.8155 - accuracy: 0.2692\n",
            "Epoch 1027/2000\n",
            "52/52 [==============================] - 0s 935us/step - loss: 1.8150 - accuracy: 0.2692\n",
            "Epoch 1028/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8151 - accuracy: 0.2692\n",
            "Epoch 1029/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8146 - accuracy: 0.2692\n",
            "Epoch 1030/2000\n",
            "52/52 [==============================] - 0s 908us/step - loss: 1.8156 - accuracy: 0.2692\n",
            "Epoch 1031/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8165 - accuracy: 0.2500\n",
            "Epoch 1032/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8170 - accuracy: 0.2308\n",
            "Epoch 1033/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8148 - accuracy: 0.2500\n",
            "Epoch 1034/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8148 - accuracy: 0.2692\n",
            "Epoch 1035/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8148 - accuracy: 0.2692\n",
            "Epoch 1036/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.2500\n",
            "Epoch 1037/2000\n",
            "52/52 [==============================] - 0s 994us/step - loss: 1.8157 - accuracy: 0.2308\n",
            "Epoch 1038/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8156 - accuracy: 0.2500\n",
            "Epoch 1039/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8133 - accuracy: 0.2308\n",
            "Epoch 1040/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8156 - accuracy: 0.2115\n",
            "Epoch 1041/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8144 - accuracy: 0.2692\n",
            "Epoch 1042/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8132 - accuracy: 0.2500\n",
            "Epoch 1043/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8146 - accuracy: 0.2500\n",
            "Epoch 1044/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8140 - accuracy: 0.2692\n",
            "Epoch 1045/2000\n",
            "52/52 [==============================] - 0s 955us/step - loss: 1.8131 - accuracy: 0.2500\n",
            "Epoch 1046/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8126 - accuracy: 0.2692\n",
            "Epoch 1047/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8129 - accuracy: 0.2692\n",
            "Epoch 1048/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8136 - accuracy: 0.2500\n",
            "Epoch 1049/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8153 - accuracy: 0.2308\n",
            "Epoch 1050/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8139 - accuracy: 0.2308\n",
            "Epoch 1051/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8148 - accuracy: 0.2308\n",
            "Epoch 1052/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8139 - accuracy: 0.2500\n",
            "Epoch 1053/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8140 - accuracy: 0.2308\n",
            "Epoch 1054/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8147 - accuracy: 0.2692\n",
            "Epoch 1055/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8146 - accuracy: 0.2500\n",
            "Epoch 1056/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.2692\n",
            "Epoch 1057/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8148 - accuracy: 0.2692\n",
            "Epoch 1058/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8162 - accuracy: 0.2500\n",
            "Epoch 1059/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8150 - accuracy: 0.2692\n",
            "Epoch 1060/2000\n",
            "52/52 [==============================] - 0s 932us/step - loss: 1.8156 - accuracy: 0.2500\n",
            "Epoch 1061/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8163 - accuracy: 0.2500\n",
            "Epoch 1062/2000\n",
            "52/52 [==============================] - 0s 957us/step - loss: 1.8153 - accuracy: 0.2308\n",
            "Epoch 1063/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8143 - accuracy: 0.2500\n",
            "Epoch 1064/2000\n",
            "52/52 [==============================] - 0s 946us/step - loss: 1.8143 - accuracy: 0.2692\n",
            "Epoch 1065/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8154 - accuracy: 0.2500\n",
            "Epoch 1066/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8140 - accuracy: 0.2500\n",
            "Epoch 1067/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.2692\n",
            "Epoch 1068/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8140 - accuracy: 0.2692\n",
            "Epoch 1069/2000\n",
            "52/52 [==============================] - 0s 995us/step - loss: 1.8135 - accuracy: 0.2692\n",
            "Epoch 1070/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8136 - accuracy: 0.2500\n",
            "Epoch 1071/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8127 - accuracy: 0.2500\n",
            "Epoch 1072/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8141 - accuracy: 0.2692\n",
            "Epoch 1073/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8142 - accuracy: 0.2692\n",
            "Epoch 1074/2000\n",
            "52/52 [==============================] - 0s 863us/step - loss: 1.8150 - accuracy: 0.2500\n",
            "Epoch 1075/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8151 - accuracy: 0.2500\n",
            "Epoch 1076/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8144 - accuracy: 0.2500\n",
            "Epoch 1077/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8144 - accuracy: 0.2692\n",
            "Epoch 1078/2000\n",
            "52/52 [==============================] - 0s 934us/step - loss: 1.8143 - accuracy: 0.2692\n",
            "Epoch 1079/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8145 - accuracy: 0.2692\n",
            "Epoch 1080/2000\n",
            "52/52 [==============================] - 0s 849us/step - loss: 1.8141 - accuracy: 0.2500\n",
            "Epoch 1081/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8158 - accuracy: 0.2692\n",
            "Epoch 1082/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8137 - accuracy: 0.2500\n",
            "Epoch 1083/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8140 - accuracy: 0.2692\n",
            "Epoch 1084/2000\n",
            "52/52 [==============================] - 0s 933us/step - loss: 1.8138 - accuracy: 0.2692\n",
            "Epoch 1085/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8139 - accuracy: 0.2692\n",
            "Epoch 1086/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8143 - accuracy: 0.2500\n",
            "Epoch 1087/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8131 - accuracy: 0.2500\n",
            "Epoch 1088/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8129 - accuracy: 0.2692\n",
            "Epoch 1089/2000\n",
            "52/52 [==============================] - 0s 921us/step - loss: 1.8134 - accuracy: 0.2692\n",
            "Epoch 1090/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8130 - accuracy: 0.2500\n",
            "Epoch 1091/2000\n",
            "52/52 [==============================] - 0s 984us/step - loss: 1.8112 - accuracy: 0.2692\n",
            "Epoch 1092/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8115 - accuracy: 0.2500\n",
            "Epoch 1093/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8123 - accuracy: 0.2692\n",
            "Epoch 1094/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8126 - accuracy: 0.2692\n",
            "Epoch 1095/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8132 - accuracy: 0.2692\n",
            "Epoch 1096/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8134 - accuracy: 0.2692\n",
            "Epoch 1097/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8131 - accuracy: 0.2692\n",
            "Epoch 1098/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8125 - accuracy: 0.2692\n",
            "Epoch 1099/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8144 - accuracy: 0.2692\n",
            "Epoch 1100/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8143 - accuracy: 0.2692\n",
            "Epoch 1101/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8138 - accuracy: 0.2692\n",
            "Epoch 1102/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.2692\n",
            "Epoch 1103/2000\n",
            "52/52 [==============================] - 0s 955us/step - loss: 1.8137 - accuracy: 0.2500\n",
            "Epoch 1104/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.2692\n",
            "Epoch 1105/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8141 - accuracy: 0.2692\n",
            "Epoch 1106/2000\n",
            "52/52 [==============================] - 0s 898us/step - loss: 1.8140 - accuracy: 0.2692\n",
            "Epoch 1107/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8139 - accuracy: 0.2692\n",
            "Epoch 1108/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8142 - accuracy: 0.2692\n",
            "Epoch 1109/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8149 - accuracy: 0.2692\n",
            "Epoch 1110/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8129 - accuracy: 0.2692\n",
            "Epoch 1111/2000\n",
            "52/52 [==============================] - 0s 901us/step - loss: 1.8135 - accuracy: 0.2692\n",
            "Epoch 1112/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8138 - accuracy: 0.2692\n",
            "Epoch 1113/2000\n",
            "52/52 [==============================] - 0s 964us/step - loss: 1.8128 - accuracy: 0.2692\n",
            "Epoch 1114/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8131 - accuracy: 0.2692\n",
            "Epoch 1115/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8122 - accuracy: 0.2500\n",
            "Epoch 1116/2000\n",
            "52/52 [==============================] - 0s 909us/step - loss: 1.8126 - accuracy: 0.2500\n",
            "Epoch 1117/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8126 - accuracy: 0.2500\n",
            "Epoch 1118/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8131 - accuracy: 0.2500\n",
            "Epoch 1119/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8123 - accuracy: 0.2308\n",
            "Epoch 1120/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8130 - accuracy: 0.2500\n",
            "Epoch 1121/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8137 - accuracy: 0.2500\n",
            "Epoch 1122/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8131 - accuracy: 0.2308\n",
            "Epoch 1123/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8125 - accuracy: 0.2692\n",
            "Epoch 1124/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8127 - accuracy: 0.2692\n",
            "Epoch 1125/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8128 - accuracy: 0.2500\n",
            "Epoch 1126/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8123 - accuracy: 0.2500\n",
            "Epoch 1127/2000\n",
            "52/52 [==============================] - 0s 986us/step - loss: 1.8118 - accuracy: 0.2692\n",
            "Epoch 1128/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8131 - accuracy: 0.2500\n",
            "Epoch 1129/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8121 - accuracy: 0.2500\n",
            "Epoch 1130/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8125 - accuracy: 0.2692\n",
            "Epoch 1131/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8130 - accuracy: 0.2692\n",
            "Epoch 1132/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8116 - accuracy: 0.2500\n",
            "Epoch 1133/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8129 - accuracy: 0.2692\n",
            "Epoch 1134/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8124 - accuracy: 0.2692\n",
            "Epoch 1135/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8128 - accuracy: 0.2692\n",
            "Epoch 1136/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8134 - accuracy: 0.2692\n",
            "Epoch 1137/2000\n",
            "52/52 [==============================] - 0s 908us/step - loss: 1.8131 - accuracy: 0.2692\n",
            "Epoch 1138/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8128 - accuracy: 0.2692\n",
            "Epoch 1139/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8119 - accuracy: 0.2692\n",
            "Epoch 1140/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8122 - accuracy: 0.2692\n",
            "Epoch 1141/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8112 - accuracy: 0.2692\n",
            "Epoch 1142/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8119 - accuracy: 0.2692\n",
            "Epoch 1143/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8112 - accuracy: 0.2500\n",
            "Epoch 1144/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8101 - accuracy: 0.2692\n",
            "Epoch 1145/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8120 - accuracy: 0.2692\n",
            "Epoch 1146/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8111 - accuracy: 0.2692\n",
            "Epoch 1147/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8115 - accuracy: 0.2500\n",
            "Epoch 1148/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8117 - accuracy: 0.2692\n",
            "Epoch 1149/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8114 - accuracy: 0.2692\n",
            "Epoch 1150/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8099 - accuracy: 0.2692\n",
            "Epoch 1151/2000\n",
            "52/52 [==============================] - 0s 882us/step - loss: 1.8100 - accuracy: 0.2692\n",
            "Epoch 1152/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8116 - accuracy: 0.2692\n",
            "Epoch 1153/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8099 - accuracy: 0.2692\n",
            "Epoch 1154/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8104 - accuracy: 0.2500\n",
            "Epoch 1155/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8112 - accuracy: 0.2692\n",
            "Epoch 1156/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8112 - accuracy: 0.2500\n",
            "Epoch 1157/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8102 - accuracy: 0.2692\n",
            "Epoch 1158/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8103 - accuracy: 0.2500\n",
            "Epoch 1159/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8100 - accuracy: 0.2692\n",
            "Epoch 1160/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8097 - accuracy: 0.2692\n",
            "Epoch 1161/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8104 - accuracy: 0.2692\n",
            "Epoch 1162/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8098 - accuracy: 0.2885\n",
            "Epoch 1163/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8107 - accuracy: 0.2885\n",
            "Epoch 1164/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8097 - accuracy: 0.2692\n",
            "Epoch 1165/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8105 - accuracy: 0.2692\n",
            "Epoch 1166/2000\n",
            "52/52 [==============================] - 0s 986us/step - loss: 1.8092 - accuracy: 0.2692\n",
            "Epoch 1167/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8088 - accuracy: 0.2692\n",
            "Epoch 1168/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8099 - accuracy: 0.2885\n",
            "Epoch 1169/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8098 - accuracy: 0.2692\n",
            "Epoch 1170/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8091 - accuracy: 0.2885\n",
            "Epoch 1171/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8097 - accuracy: 0.2692\n",
            "Epoch 1172/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8104 - accuracy: 0.2692\n",
            "Epoch 1173/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8108 - accuracy: 0.2692\n",
            "Epoch 1174/2000\n",
            "52/52 [==============================] - 0s 961us/step - loss: 1.8104 - accuracy: 0.2692\n",
            "Epoch 1175/2000\n",
            "52/52 [==============================] - 0s 919us/step - loss: 1.8125 - accuracy: 0.2500\n",
            "Epoch 1176/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8106 - accuracy: 0.2692\n",
            "Epoch 1177/2000\n",
            "52/52 [==============================] - 0s 949us/step - loss: 1.8108 - accuracy: 0.2885\n",
            "Epoch 1178/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8128 - accuracy: 0.2500\n",
            "Epoch 1179/2000\n",
            "52/52 [==============================] - 0s 893us/step - loss: 1.8107 - accuracy: 0.2500\n",
            "Epoch 1180/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8114 - accuracy: 0.2500\n",
            "Epoch 1181/2000\n",
            "52/52 [==============================] - 0s 956us/step - loss: 1.8097 - accuracy: 0.2500\n",
            "Epoch 1182/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8091 - accuracy: 0.2885\n",
            "Epoch 1183/2000\n",
            "52/52 [==============================] - 0s 955us/step - loss: 1.8087 - accuracy: 0.2500\n",
            "Epoch 1184/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8097 - accuracy: 0.2692\n",
            "Epoch 1185/2000\n",
            "52/52 [==============================] - 0s 930us/step - loss: 1.8097 - accuracy: 0.2500\n",
            "Epoch 1186/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8087 - accuracy: 0.2692\n",
            "Epoch 1187/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8094 - accuracy: 0.2500\n",
            "Epoch 1188/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8097 - accuracy: 0.2500\n",
            "Epoch 1189/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8093 - accuracy: 0.2692\n",
            "Epoch 1190/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8094 - accuracy: 0.2692\n",
            "Epoch 1191/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8090 - accuracy: 0.2500\n",
            "Epoch 1192/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8085 - accuracy: 0.2500\n",
            "Epoch 1193/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8092 - accuracy: 0.2692\n",
            "Epoch 1194/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8094 - accuracy: 0.2500\n",
            "Epoch 1195/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8088 - accuracy: 0.2692\n",
            "Epoch 1196/2000\n",
            "52/52 [==============================] - 0s 938us/step - loss: 1.8092 - accuracy: 0.2500\n",
            "Epoch 1197/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.2500\n",
            "Epoch 1198/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8083 - accuracy: 0.2500\n",
            "Epoch 1199/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8067 - accuracy: 0.2692\n",
            "Epoch 1200/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8074 - accuracy: 0.2500\n",
            "Epoch 1201/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1202/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8059 - accuracy: 0.2500\n",
            "Epoch 1203/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8069 - accuracy: 0.2500\n",
            "Epoch 1204/2000\n",
            "52/52 [==============================] - 0s 930us/step - loss: 1.8086 - accuracy: 0.2500\n",
            "Epoch 1205/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8069 - accuracy: 0.2500\n",
            "Epoch 1206/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8082 - accuracy: 0.2500\n",
            "Epoch 1207/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8065 - accuracy: 0.2500\n",
            "Epoch 1208/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8063 - accuracy: 0.2500\n",
            "Epoch 1209/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8076 - accuracy: 0.2500\n",
            "Epoch 1210/2000\n",
            "52/52 [==============================] - 0s 993us/step - loss: 1.8061 - accuracy: 0.2500\n",
            "Epoch 1211/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2692\n",
            "Epoch 1212/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8071 - accuracy: 0.2692\n",
            "Epoch 1213/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8059 - accuracy: 0.2692\n",
            "Epoch 1214/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8067 - accuracy: 0.2692\n",
            "Epoch 1215/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2500\n",
            "Epoch 1216/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8067 - accuracy: 0.2308\n",
            "Epoch 1217/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8063 - accuracy: 0.2500\n",
            "Epoch 1218/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8065 - accuracy: 0.2500\n",
            "Epoch 1219/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2500\n",
            "Epoch 1220/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.2500\n",
            "Epoch 1221/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8063 - accuracy: 0.2500\n",
            "Epoch 1222/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8070 - accuracy: 0.2692\n",
            "Epoch 1223/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.2500\n",
            "Epoch 1224/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1225/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8087 - accuracy: 0.2500\n",
            "Epoch 1226/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8072 - accuracy: 0.2692\n",
            "Epoch 1227/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1228/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8088 - accuracy: 0.2500\n",
            "Epoch 1229/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8080 - accuracy: 0.2500\n",
            "Epoch 1230/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.2500\n",
            "Epoch 1231/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8069 - accuracy: 0.2500\n",
            "Epoch 1232/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8084 - accuracy: 0.2692\n",
            "Epoch 1233/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8077 - accuracy: 0.2692\n",
            "Epoch 1234/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1235/2000\n",
            "52/52 [==============================] - 0s 940us/step - loss: 1.8062 - accuracy: 0.2692\n",
            "Epoch 1236/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8075 - accuracy: 0.2500\n",
            "Epoch 1237/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8070 - accuracy: 0.2692\n",
            "Epoch 1238/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8070 - accuracy: 0.2692\n",
            "Epoch 1239/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8055 - accuracy: 0.2692\n",
            "Epoch 1240/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8068 - accuracy: 0.2692\n",
            "Epoch 1241/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8051 - accuracy: 0.2692\n",
            "Epoch 1242/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8060 - accuracy: 0.2692\n",
            "Epoch 1243/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8048 - accuracy: 0.2692\n",
            "Epoch 1244/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8069 - accuracy: 0.2692\n",
            "Epoch 1245/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1246/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8066 - accuracy: 0.2692\n",
            "Epoch 1247/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2692\n",
            "Epoch 1248/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8057 - accuracy: 0.2692\n",
            "Epoch 1249/2000\n",
            "52/52 [==============================] - 0s 911us/step - loss: 1.8051 - accuracy: 0.2692\n",
            "Epoch 1250/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8060 - accuracy: 0.2692\n",
            "Epoch 1251/2000\n",
            "52/52 [==============================] - 0s 987us/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1252/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2500\n",
            "Epoch 1253/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8053 - accuracy: 0.2692\n",
            "Epoch 1254/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8048 - accuracy: 0.2692\n",
            "Epoch 1255/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2692\n",
            "Epoch 1256/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8063 - accuracy: 0.2500\n",
            "Epoch 1257/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8058 - accuracy: 0.2500\n",
            "Epoch 1258/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1259/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8059 - accuracy: 0.2500\n",
            "Epoch 1260/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.2500\n",
            "Epoch 1261/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8040 - accuracy: 0.2500\n",
            "Epoch 1262/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.2500\n",
            "Epoch 1263/2000\n",
            "52/52 [==============================] - 0s 939us/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1264/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8051 - accuracy: 0.2500\n",
            "Epoch 1265/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2308\n",
            "Epoch 1266/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8048 - accuracy: 0.2500\n",
            "Epoch 1267/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1268/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8047 - accuracy: 0.2500\n",
            "Epoch 1269/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8057 - accuracy: 0.2500\n",
            "Epoch 1270/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8061 - accuracy: 0.2500\n",
            "Epoch 1271/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8062 - accuracy: 0.2500\n",
            "Epoch 1272/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8067 - accuracy: 0.2500\n",
            "Epoch 1273/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8061 - accuracy: 0.2500\n",
            "Epoch 1274/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8059 - accuracy: 0.2692\n",
            "Epoch 1275/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8060 - accuracy: 0.2500\n",
            "Epoch 1276/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8065 - accuracy: 0.2500\n",
            "Epoch 1277/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8069 - accuracy: 0.2500\n",
            "Epoch 1278/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8050 - accuracy: 0.2500\n",
            "Epoch 1279/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8060 - accuracy: 0.2500\n",
            "Epoch 1280/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2500\n",
            "Epoch 1281/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8045 - accuracy: 0.2500\n",
            "Epoch 1282/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8043 - accuracy: 0.2500\n",
            "Epoch 1283/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1284/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8054 - accuracy: 0.2500\n",
            "Epoch 1285/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8050 - accuracy: 0.2500\n",
            "Epoch 1286/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8045 - accuracy: 0.2500\n",
            "Epoch 1287/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8041 - accuracy: 0.2500\n",
            "Epoch 1288/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8042 - accuracy: 0.2500\n",
            "Epoch 1289/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8051 - accuracy: 0.2500\n",
            "Epoch 1290/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8043 - accuracy: 0.2500\n",
            "Epoch 1291/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.2500\n",
            "Epoch 1292/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8043 - accuracy: 0.2500\n",
            "Epoch 1293/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8040 - accuracy: 0.2692\n",
            "Epoch 1294/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.2500\n",
            "Epoch 1295/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1296/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8041 - accuracy: 0.2500\n",
            "Epoch 1297/2000\n",
            "52/52 [==============================] - 0s 958us/step - loss: 1.8060 - accuracy: 0.2500\n",
            "Epoch 1298/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8038 - accuracy: 0.2692\n",
            "Epoch 1299/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8037 - accuracy: 0.2500\n",
            "Epoch 1300/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8053 - accuracy: 0.2500\n",
            "Epoch 1301/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8042 - accuracy: 0.2500\n",
            "Epoch 1302/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1303/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8065 - accuracy: 0.2500\n",
            "Epoch 1304/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8057 - accuracy: 0.2500\n",
            "Epoch 1305/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8062 - accuracy: 0.2500\n",
            "Epoch 1306/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8067 - accuracy: 0.2500\n",
            "Epoch 1307/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1308/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2500\n",
            "Epoch 1309/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8057 - accuracy: 0.2500\n",
            "Epoch 1310/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1311/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8060 - accuracy: 0.2500\n",
            "Epoch 1312/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8050 - accuracy: 0.2500\n",
            "Epoch 1313/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8046 - accuracy: 0.2500\n",
            "Epoch 1314/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1315/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8063 - accuracy: 0.2500\n",
            "Epoch 1316/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8056 - accuracy: 0.2500\n",
            "Epoch 1317/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1318/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8045 - accuracy: 0.2500\n",
            "Epoch 1319/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8054 - accuracy: 0.2500\n",
            "Epoch 1320/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8038 - accuracy: 0.2500\n",
            "Epoch 1321/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8047 - accuracy: 0.2500\n",
            "Epoch 1322/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8033 - accuracy: 0.2500\n",
            "Epoch 1323/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8044 - accuracy: 0.2500\n",
            "Epoch 1324/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8080 - accuracy: 0.2500\n",
            "Epoch 1325/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8077 - accuracy: 0.2500\n",
            "Epoch 1326/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8055 - accuracy: 0.2500\n",
            "Epoch 1327/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1328/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8067 - accuracy: 0.2500\n",
            "Epoch 1329/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8054 - accuracy: 0.2500\n",
            "Epoch 1330/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2500\n",
            "Epoch 1331/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8064 - accuracy: 0.2500\n",
            "Epoch 1332/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8061 - accuracy: 0.2500\n",
            "Epoch 1333/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.2500\n",
            "Epoch 1334/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8057 - accuracy: 0.2500\n",
            "Epoch 1335/2000\n",
            "52/52 [==============================] - 0s 862us/step - loss: 1.8054 - accuracy: 0.2500\n",
            "Epoch 1336/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8038 - accuracy: 0.2500\n",
            "Epoch 1337/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8039 - accuracy: 0.2500\n",
            "Epoch 1338/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8032 - accuracy: 0.2500\n",
            "Epoch 1339/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8039 - accuracy: 0.2500\n",
            "Epoch 1340/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8048 - accuracy: 0.2692\n",
            "Epoch 1341/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8040 - accuracy: 0.2500\n",
            "Epoch 1342/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8030 - accuracy: 0.2500\n",
            "Epoch 1343/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8035 - accuracy: 0.2500\n",
            "Epoch 1344/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8037 - accuracy: 0.2500\n",
            "Epoch 1345/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8042 - accuracy: 0.2500\n",
            "Epoch 1346/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8033 - accuracy: 0.2500\n",
            "Epoch 1347/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8046 - accuracy: 0.2500\n",
            "Epoch 1348/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8032 - accuracy: 0.2500\n",
            "Epoch 1349/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8034 - accuracy: 0.2500\n",
            "Epoch 1350/2000\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8035 - accuracy: 0.2500\n",
            "Epoch 1351/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8033 - accuracy: 0.2500\n",
            "Epoch 1352/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8041 - accuracy: 0.2500\n",
            "Epoch 1353/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8041 - accuracy: 0.2500\n",
            "Epoch 1354/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1355/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8037 - accuracy: 0.2692\n",
            "Epoch 1356/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1357/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.2692\n",
            "Epoch 1358/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8053 - accuracy: 0.2500\n",
            "Epoch 1359/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8052 - accuracy: 0.2500\n",
            "Epoch 1360/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8051 - accuracy: 0.2500\n",
            "Epoch 1361/2000\n",
            "52/52 [==============================] - 0s 928us/step - loss: 1.8050 - accuracy: 0.2692\n",
            "Epoch 1362/2000\n",
            "52/52 [==============================] - 0s 936us/step - loss: 1.8034 - accuracy: 0.2500\n",
            "Epoch 1363/2000\n",
            "52/52 [==============================] - 0s 951us/step - loss: 1.8029 - accuracy: 0.2500\n",
            "Epoch 1364/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8035 - accuracy: 0.2500\n",
            "Epoch 1365/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8055 - accuracy: 0.2692\n",
            "Epoch 1366/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8037 - accuracy: 0.2500\n",
            "Epoch 1367/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8023 - accuracy: 0.2500\n",
            "Epoch 1368/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8029 - accuracy: 0.2500\n",
            "Epoch 1369/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8027 - accuracy: 0.2500\n",
            "Epoch 1370/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8017 - accuracy: 0.2500\n",
            "Epoch 1371/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8017 - accuracy: 0.2308\n",
            "Epoch 1372/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8038 - accuracy: 0.2500\n",
            "Epoch 1373/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8017 - accuracy: 0.2500\n",
            "Epoch 1374/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8014 - accuracy: 0.2500\n",
            "Epoch 1375/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8016 - accuracy: 0.2500\n",
            "Epoch 1376/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8006 - accuracy: 0.2500\n",
            "Epoch 1377/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8025 - accuracy: 0.2500\n",
            "Epoch 1378/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8002 - accuracy: 0.2500\n",
            "Epoch 1379/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8003 - accuracy: 0.2500\n",
            "Epoch 1380/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8012 - accuracy: 0.2500\n",
            "Epoch 1381/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8017 - accuracy: 0.2500\n",
            "Epoch 1382/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8017 - accuracy: 0.2500\n",
            "Epoch 1383/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8005 - accuracy: 0.2500\n",
            "Epoch 1384/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8006 - accuracy: 0.2500\n",
            "Epoch 1385/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8011 - accuracy: 0.2500\n",
            "Epoch 1386/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8009 - accuracy: 0.2500\n",
            "Epoch 1387/2000\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8005 - accuracy: 0.2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1RAGxmQ3682",
        "outputId": "23c4c7ca-d757-4db4-c587-927e39fc5bda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network.weights"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense/kernel:0' shape=(12, 2) dtype=float32, numpy=\n",
              " array([[  1.3611581 ,   4.8292747 ],\n",
              "        [ -5.3851066 ,  -3.5424724 ],\n",
              "        [ -0.22258565,  -7.381455  ],\n",
              "        [ -3.2595515 ,  10.845241  ],\n",
              "        [ -1.5443897 ,   0.39600402],\n",
              "        [ -6.5328517 ,  -2.1580758 ],\n",
              "        [  3.071938  ,   1.7843106 ],\n",
              "        [  2.3099737 , -12.405987  ],\n",
              "        [  1.0185207 ,   6.6893554 ],\n",
              "        [ -2.4491675 ,  -4.4333196 ],\n",
              "        [ -1.159435  ,  -9.701969  ],\n",
              "        [  1.9205511 ,   5.171864  ]], dtype=float32)>,\n",
              " <tf.Variable 'dense/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.5678108, -2.4891574], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/kernel:0' shape=(2, 12) dtype=float32, numpy=\n",
              " array([[-6.9726863, -6.861254 , -7.3220673, -6.017372 , -6.876631 ,\n",
              "         -6.628013 , -7.330283 , -7.5383554, -6.888759 , -7.1045756,\n",
              "         -7.1892977, -7.0650864],\n",
              "        [ 7.178388 ,  6.7969904,  6.8868537,  7.094134 ,  7.016617 ,\n",
              "          6.791733 ,  7.302099 ,  6.9929857,  7.135802 ,  6.8844852,\n",
              "          6.950604 ,  7.202671 ]], dtype=float32)>,\n",
              " <tf.Variable 'dense_1/bias:0' shape=(12,) dtype=float32, numpy=\n",
              " array([-11.091062, -14.161408, -11.653249, -13.465105, -10.600672,\n",
              "        -15.618717, -10.817305, -11.371742, -11.181882, -12.125293,\n",
              "        -11.625672, -10.490658], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo90F8XD7nBY"
      },
      "source": [
        "# a=network.weights[0]\n",
        "# a.numpy()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwcAOlqK37Ds",
        "outputId": "53ee0674-0cb0-4dd1-ecc3-81deafc5ba19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "d2 = pd.DataFrame(  network.weights[0].numpy(),  columns = ['x1', 'x2'] )\n",
        "w2v_df = pd.concat( [w2idx,d2],axis=1 )\n",
        "w2v_df"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>values</th>\n",
              "      <th>word</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>prince</td>\n",
              "      <td>1.361158</td>\n",
              "      <td>4.829275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wise</td>\n",
              "      <td>-5.385107</td>\n",
              "      <td>-3.542472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>queen</td>\n",
              "      <td>-0.222586</td>\n",
              "      <td>-7.381455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>strong</td>\n",
              "      <td>-3.259552</td>\n",
              "      <td>10.845241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>young</td>\n",
              "      <td>-1.544390</td>\n",
              "      <td>0.396004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>pretty</td>\n",
              "      <td>-6.532852</td>\n",
              "      <td>-2.158076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>man</td>\n",
              "      <td>3.071938</td>\n",
              "      <td>1.784311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>woman</td>\n",
              "      <td>2.309974</td>\n",
              "      <td>-12.405987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>boy</td>\n",
              "      <td>1.018521</td>\n",
              "      <td>6.689355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>girl</td>\n",
              "      <td>-2.449167</td>\n",
              "      <td>-4.433320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>princess</td>\n",
              "      <td>-1.159435</td>\n",
              "      <td>-9.701969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>king</td>\n",
              "      <td>1.920551</td>\n",
              "      <td>5.171864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    values      word        x1         x2\n",
              "0        0    prince  1.361158   4.829275\n",
              "1        1      wise -5.385107  -3.542472\n",
              "2        2     queen -0.222586  -7.381455\n",
              "3        3    strong -3.259552  10.845241\n",
              "4        4     young -1.544390   0.396004\n",
              "5        5    pretty -6.532852  -2.158076\n",
              "6        6       man  3.071938   1.784311\n",
              "7        7     woman  2.309974 -12.405987\n",
              "8        8       boy  1.018521   6.689355\n",
              "9        9      girl -2.449167  -4.433320\n",
              "10      10  princess -1.159435  -9.701969\n",
              "11      11      king  1.920551   5.171864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn6I3PWC8x8E",
        "outputId": "404d23af-0788-4100-f20a-71e7fe6a245e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x1 = np.array(w2v_df['x1'])\n",
        "x2 = np.array(w2v_df['x2'])\n",
        "plt.close()\n",
        "PADDING = .1\n",
        "x_axis_min, x_axis_max = np.min(x1)-PADDING, np.max(x1)+PADDING\n",
        "y_axis_min, y_axis_max = np.min(x2)-PADDING, np.max(x2)+PADDING\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
        "# plt.figure(figsize=(10,10))\n",
        "\n",
        "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
        "    ax.annotate(word, (x1,x2 ))\n",
        "    \n",
        "plt.xlim(x_axis_min,x_axis_max)\n",
        "plt.ylim(y_axis_min,y_axis_max)\n",
        "\n",
        "# plt.scatter(x1, x2, c='red', alpha=0.5)\n",
        "plt.show()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD/CAYAAAAAJProAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3QV5b3/8feXAMkxeEAhoCiyseUakpCdoMYQEBShGqWIiPywq0ABD7W1+KtIPboAUVsVipeKF6wYqwUpN+ut3LFcipILUAIGyNFdCoKG04AEBHN5fn8k5kcEHAvZmVw+r7VY2bPn2c98n1lZ+fDMzJ4x5xwiIiLfppHfBYiISO2nsBAREU8KCxER8aSwEBERTwoLERHxpLAQERFPCgupUWY2wczO87sOEfn3mL5nITXJzEJAsnPu4GnWRTjnSmu+KhHxopmFhI2ZRZvZu2a21cxyzWwK0BZYY2ZrKtoUmdlvzWwrkGJm/7eiba6ZTahoEzCzj8zsJTPbbmbLzew/Ktb1NLO/m9kWM5tuZrm+DVikHlNYSDgNBD51ziU457oDTwGfAn2dc30r2kQDHzrnEoAvgVHAlcBVwFgzS6xo1xGY5ZyLBQ4BQyrefwW40znXA9CsRCRMFBYSTtuA/mb2uJmlOecOn6ZNKbCo4nUvYIlz7qhzrghYDKRVrPvEObel4nU2EDCzFsD5zrmNFe/PDc8wRKSx3wVI/eWc22VmQeAG4BEzW3WaZse/43mKEye9LgX+ozpqFJHvplad4G7VqpULBAJ+lyHV5KuvvqJx48Y0atSIQ4cOcfDgQU6cOMH3v/99IiMjAdi8eTOJieVHmo4dO0YoFKJLly4458jLy6NDhw5ERESQn59PbGwsAAcOHKCsrIy2bduyfft2AoEA0dHR7Nu3j0OHDlW2E2kosrOzDzrnYsK5jVoVFsnJyS4rK8vvMqSaLFu2jIkTJ9KoUSOaNGnC888/z8aNG3n22Wdp27Yta9asoVmzZhQVFVV+ZubMmcyZMweAMWPGMGHCBEKhEOnp6eTmlp+7njFjBkVFRUydOpUPP/yQsWPH0qhRI/r06UNWVhYbNmzwZbwifjGzbOdccli3obCQuqyoqIhmzZoB8Nhjj7F//36efvppn6sSqVk1ERY6ZyF12rvvvstvfvMbSkpKaN++PRkZGX6XJFIvaWYhIlLH1cTMQpfOioiIp2oJCzObY2afn/ztWTO70MxWmNnuip8XVMe2RESk5lXXzCKD8m/rnuxXwCrnXEdgVcWyiIjUQdUSFs65tcC/vvH2IODVitevAj+sjm2JiEjNC+c5izbOuf0Vrw8AbU7XyMzGmVmWmWUVFBSEsRwRETlbNXKC25VfcnXay66cc7Odc8nOueSYmLB+AVFERM5SOMPiMzO7GKDi5+dh3JaIiIRROMPiLeDHFa9/DPw5jNsSEZEwqq5LZ+cBG4HOZrbXzH4CPEb57al3A9dVLIuISB1ULbf7cM4NP8Oqa6ujfxER8Ze+wS0iIp4UFiIi4klhISIinhQWIiLiSWEhIiKeFBYiIuJJYSEiIp4UFiIi4klhISIinhQWIiLiSWEhIiKeFBYiIuJJYSEiIp4UFiIi4klhISIinhQWIiLiSWEhIiKeFBYiIuJJYSEitVooFKJ79+5+l9HgKSxERMSTwkJEar2SkhJGjBhB165dufXWWzl27BirVq0iMTGRuLg4Ro8ezYkTJ1i9ejU//OEPKz+3YsUKBg8e7GPl9YfCQkRqvZ07d/LTn/6Ujz76iP/8z/9k5syZjBw5kvnz57Nt2zZKSkp4/vnn6du3L3l5eRQUFADwyiuvMHr0aJ+rrx8UFiJS67Vr147U1FQA7rjjDlatWkWHDh3o1KkTAD/+8Y9Zu3YtZsaPfvQjXn/9dQ4dOsTGjRv5wQ9+4Gfp9UZjvwsQEfFiZlWWW7Rowf/+7/+etu2oUaO46aabiIqKYujQoTRurD9z1UEzCxGp9fbs2cPGjRsBmDt3LsnJyYRCIfLz8wF47bXX6NOnDwBt27albdu2PPLII4waNcq3musbhYWI1HqdO3dm1qxZdO3alcLCQu655x5eeeUVhg4dSlxcHI0aNeK//uu/KtuPGDGCdu3a0bVrVx+rrl80PxORWi0QCJCXl3fK+9deey2bN28+7WfWr1/P2LFjw11ag6KwEJF6JSkpiejoaH7729/6XUq9orAQkXolOzvb7xLqJZ2zEBERTwoLERHxpLAQERFPCgsRkTM43R1vs7KyuPvuu32qyD86wS0i8m9ITk4mOTnZ7zJqnGYWIiLfwccff0xiYiLTp08nPT0dgKlTpzJ69GiuueYaLr/8cp555pnK9g8//DCdO3emV69eDB8+nBkzZvhVerVQWIhIgzR58mRWrlz5ndru3LmTIUOGkJGRQc+ePausy8vLY9myZWzatImHHnqI4uJiMjMzWbRoEVu3buUvf/kLWVlZ4RhCjdJhKBFpcEpLS5k2bdp3altQUMCgQYNYvHgx3bp14/3336+y/sYbbyQyMpLIyEhat27NZ599xoYNGxg0aBBRUVFERUVx0003hWEUNSvsMwszC5nZNjPbYmZ1P15FpFYLhUJ06dLllIclBQIBJk2aRDAYZMGCBYwcOZKFCxcC5bcUmTJlCsFgkLi4uMrbixw9epTjx4+zd+9err/+ehYtWgSUB0hKSgovvvgi8+fPp6ioCICIiAhKSkr8GXiY1dRhqL7OuR7OuYZ3VkhEatw3H5b03HPPAdCyZUtycnK4/fbbT/lMq1atyMnJYfz48ZXnF373u9/RpEkTPvvsMwKBAP/61784fPgw+fn5rFy5kjvvvJN27doxc+bMKn2lpqby9ttvc/z4cYqKinjnnXfCP+gw02EoEal3vvmwpK9PPA8bNuyMn7nllluA8ntLLV68GCi/IeGFF15IdHQ077zzDv3792fgwIEcOXKE1NRUDhw4gHOOiy66qEpfPXv25OabbyY+Pp42bdoQFxdH8+bNwzHUGlMTYeGA5WbmgBedc7NPXmlm44BxAJdddlkNlCMi9d03H5b09XJ0dPQZPxMZGQlUPZQUGRnJkiVLgPIHLmVmZvL2228zZMgQ5s2bd0ofubm5la/vvfdepk6dyrFjx+jduzdJSUnnNiif1cRhqF7OuSDwA+AuM+t98krn3GznXLJzLjkmJqYGyhGR+u6bD0vq1avXWfXTv39/Zs2aVblcWFjIVVddxYYNGyofvHT06FF27dp1ymfHjRtHjx49CAaDDBkyhGAweFY11BZhDwvn3L6Kn58DS4Arwr1NEWnYvvmwpPHjx59VPw8++CCFhYV0796dhIQE1qxZQ0xMDBkZGQwfPpz4+HhSUlJO+7yNuXPnsmXLFvLy8rj//vvPdUi+M+dc+Do3iwYaOeeOVLxeAUxzzi09Xfvk5GRXH65HFhH/hEIh0tPTqxwSqu/MLDvcFxCF+5xFG2BJxfHCxsDcMwWFiIjUXmENC+fcx0BCOLchInKyQCDQoGYVNUW3+xAREU8KCxER8aSwEBERTwoLERHxpLAQERFPCgsREfGksBAREU8KCxER8aSwEBERTwoLERHxpLAQERFPCgsREfGksBAREU8KCxER8aSwEBERTwoLERHxpLAQERFPCgsREfGksBAREU8KCxGROigUCtGlSxdGjhwJ0N3M/mhm15nZBjPbbWZXVPzbaGabzexvZtYZwMxGmtliM1ta0fYJr+0pLERE6qj8/Hx++ctfAuQCXYD/A/QC7gX+G8gD0pxzicBk4NcnfbwHMAyIA4aZWbtv21bjaq9eRERqRIcOHYiLi/t6cTuwyjnnzGwbEACaA6+aWUfAAU1O+vgq59xhADPbAbQH/nmmbWlmISJSR0VGRp68WAacOOl1Y+BhYI1zrjtwExB1UvsTJ70uxWPyoLAQEam/mgP7Kl6PPJeOFBYiIvXXE8BvzGwz53jawZxz1VNSNUhOTnZZWVl+lyEiUqeYWbZzLjmc29DMQkREPCksRETEk8JCREQ8KSxERMSTwkJERDwpLERExJPCQuQcTZ48maeeeqpy+YEHHuDpp59m4sSJdO/enbi4OObPnw/A+++/T3p6emXbn/3sZ2RkZAAQCASYMmUKwWCQuLg48vLyACgoKKB///7ExsYyZswY2rdvz8GDB2tugCIoLETO2ejRo/nDH/4AQFlZGW+88QaXXnopW7ZsYevWraxcuZKJEyeyf/9+z75atWpFTk4O48ePZ8aMGQA89NBD9OvXj+3bt3PrrbeyZ8+esI5H5HQUFiLnKBAI0LJlSzZv3szy5ctJTExk/fr1DB8+nIiICNq0aUOfPn3IzMz07OuWW24BICkpiVAoBMD69eu5/fbbARg4cCAXXHBB2MYicia666xINRgzZgwZGRkcOHCA0aNHs2LFitO2a9y4MWVlZZXLx48fr7L+6xvDRUREUFJSEr6CRf5NmlmIVIPBgwezdOlSMjMzGTBgAGlpacyfP5/S0lIKCgpYu3YtV1xxBe3bt2fHjh2cOHGCQ4cOsWrVKs++U1NT+dOf/gTA8uXLKSwsDPdwRE6hmYVINWjatCl9+/alRYsWREREMHjwYDZu3EhCQgJmxhNPPMFFF10EwG233Ub37t3p0KEDiYmJnn1PmTKF4cOH89prr5GSksJFF13E+eefH+4hiVQR9hsJmtlA4GkgAvi9c+6xM7XVjQSlriorKyMYDLJgwQI6duxYrX2fOHGCiIgIGjduzMaNGxk/fjxbtmyp1m1I3VYTNxIM68zCzCKAWUB/YC+QaWZvOed2hHO7IjVpx44dpKenM3jw4GoPCoA9e/Zw2223UVZWRtOmTXnppZeqfRsiXsJ9GOoKIN859zGAmb0BDAIUFlJvdOvWjY8//jhs/Xfs2JHNmzeHrX+R7yLcJ7gvoeozXfdWvFfJzMaZWZaZZRUUFIS5HBERORu+Xw3lnJvtnEt2ziXHxMT4XY6IiJxGuMNiH9DupOVL+f/PgxURkToi3GGRCXQ0sw5m1hS4HXgrzNsUEZFqFtYT3M65EjP7GbCM8ktn5zjntodzmyIiUv3C/qU859x7wHvh3o6IiISP7ye4RUSk9lNYiIiIJ4WFiIh4UliIiIgnhYWIiHhSWIiIiCeFhYiIeKrXYfHUU09x7NixyuVf//rXPlYjIlJ31fmwKC0tPeM6hYWISPWo1Y9VDYVCDBw4kKSkJHJycoiNjeUPf/gD3bp1Y9iwYaxYsYL77ruPCy+8kClTpnDixAm+973v8corrzBnzhw+/fRT+vbtS6tWrbjyyiv58ssv6dGjB7GxsXzve9/jwgsvZMKECQA88MADtG7dml/84hc+j1pEpBZyztWaf0lJSe5kn3zyiQPc+vXrnXPOjRo1yk2fPt21b9/ePf7448455woKClxaWporKipyzjn32GOPuYceesg551z79u1dQUFBZX/R0dFV+k5MTHTOOVdaWuouv/xyd/DgQSciUtcAWS7Mf59r9cwCoF27dqSmpgJwxx138MwzzwAwbNgwAD744AN27NhR2earr74iJSXFs99AIEDLli3ZvHkzn332GYmJibRs2TJMoxARqdtqfViY2WmXo6OjgfKZUf/+/Zk3b96/3feYMWPIyMjgwIEDjB49+tyLFRGpp2r9Ce49e/awceNGAObOnUuvXr2qrL/qqqvYsGED+fn5ABw9epRdu3YBcP7553PkyJHKtk2aNKG4uLhyefDgwSxdupTMzEwGDBgQ7qGIiNRZtT4sOnfuzKxZs+jatSuFhYWMHz++yvqYmBgyMjIYPnw48fHxpKSkkJeXB8C4ceMYOHAgffv2rVyOj49nxIgRADRt2pS+ffty2223ERERUbMDExGpQ6z83EjtkJyc7LKysiqXQ6EQ6enp5ObmhmV7ZWVlBINBFixYQMeOHcOyDRGRcDOzbOdccji3UetnFuGyY8cOvv/973PttdcqKEREPNTqmYWIiHjTzEJERGoFhYWIiHhSWITJDTfcwKFDh/wuQ0SkWtT6L+XVVe+9957fJYiIVBvNLM7S9OnTK289cs8999CvXz8AVq9ezYgRIwgEAhw8eJCjR49y4403kpCQQPfu3Zk/fz4A2dnZ9OnTh6SkJAYMGMD+/ft9G4uIiBeFxVlKS0tj3bp1AGRlZVFUVERxcTHr1q2jd+/ele2WLl1K27Zt2bp1K7m5uQwcOJDi4mJ+/vOfs3DhQrKzsxk9ejQPPPCAX0MREfGksDhLSUlJZGdn88UXXxAZGUlKSgpZWVmsW7eOtLS0ynZxcXGsWLGCSZMmsW7dOpo3b87OnTvJzc2lf//+9OjRg0ceeYS9e/f6OBoRkW+ncxZnqUmTJnTo0IGMjAyuvvpq4uPjWbNmDfn5+XTt2rWyXadOncjJyeG9997jwQcf5Nprr2Xw4MHExsZW3vNKRKS208ziHKSlpTFjxgx69+5NWloaL7zwAomJiVXulPvpp59y3nnncccddzBx4kRycnLo3LkzBQUFlWFRXFzM9u3b/RqGiIgnzSzOQVpaGo8++igpKSlER0cTFRVV5RAUwLZt25g4cSKNGjWiSZMmPP/88zRt2pSFCxdy9913c/jwYUpKSpgwYQKxsbE+jURE5Nvpdh9S702ePJnevXtz3XXXnbJu5MiRpKenc+utt/pQmUj1qInbfWhmIfXetGnTTvt+aWlpDVciUncpLKReefjhh3n99deJiYmhXbt2JCUlkZubWzl7CAQCDBs2jBUrVnDffff5Xa5InaGwkHojMzOTRYsWsXXrVoqLiwkGgyQlJZ3SrmXLluTk5ADl34MREW8KC6k3NmzYwKBBg4iKiiIqKoqbbrrptO2GDRtWw5WJ1H26dFYanOjoaL9LEKlzFBZSb6SmpvL2229z/PhxioqKeOedd/wuSaTe0GEoqTd69uzJzTffTHx8PG3atCEuLo7mzZv7XZZIvaDvWUi9UlRURLNmzTh27Bi9e/dm9uzZBINBv8sSCas6/VhVM5tqZvvMbEvFvxvCtS2Rr40bN44ePXoQDAYZMmSIgkKkmoT7MNSTzrkZYd6GSKW5c+f6XYJIvaQT3CIi4incYfEzM/u7mc0xswtO18DMxplZlpllFRQUhLkcERE5G+d0gtvMVgIXnWbVA8AHwEHAAQ8DFzvnRn9bfzrBLSLy76v1NxJ0zp16G8/TMLOXAF30LiJSR4XzaqiLT1ocDOSGa1siIhJe4bwa6gkz60H5YagQcGcYtyUiImEUtrBwzv0oXH2LiEjN0qWzIiLiSWEhIiKeFBYiIuJJYSEiIp4UFiIi4klhISIinhQWIiLiSWEhIiKeFBYiIuJJYSEiIp4UFiIi4klhIdKAPfroo3Tq1IlevXoxfPhwZsyYwTXXXMPXz5U5ePAggUAAgNLSUiZOnEjPnj2Jj4/nxRdfrOxn+vTple9PmTIFgFAoRNeuXRk7diyxsbFcf/31fPnllzU+RqkeCguRBio7O5s33niDLVu28N5775GZmfmt7V9++WWaN29OZmYmmZmZvPTSS3zyyScsX76c3bt3s2nTJrZs2UJ2djZr164FYPfu3dx1111s376dFi1asGjRopoYmoRBOG9RLiK12Lp16xg8eDDnnXceADfffPO3tl++fDl///vfWbhwIQCHDx9m9+7dLF++nOXLl5OYmAhAUVERu3fv5rLLLqNDhw706NEDgKSkJEKhUPgGJGGlsBCRKho3bkxZWRkAx48fr3zfOcfvfvc7BgwYUKX9smXLuP/++7nzzqqPrAmFQkRGRlYuR0RE6DBUHabDUCINVO/evXnzzTf58ssvOXLkCG+//TYAgUCA7OxsgMpZBMCAAQN4/vnnKS4uBmDXrl0cPXqUAQMGMGfOHIqKigDYt28fn3/+eQ2PRsJNMwuRBioYDDJs2DASEhJo3bo1PXv2BODee+/ltttuY/bs2dx4442V7ceMGUMoFCIYDOKcIyYmhjfffJPrr7+ejz76iJSUFACaNWvG66+/TkREhC/jkvAw55zfNVRKTk52X1+FISI1a+rUqTRr1ox7773X71Lk32Rm2c655HBuQ4ehRETEkw5DiQhQPrMQORPNLERExJPCQkREPCksRETEk8JCREQ8KSxERMSTwkJERDwpLERExJPCQkREPCksRETEk8JCREQ8KSxERMSTwkKklps8eTIrV670uwxp4HQjQZFarLS0lGnTpvldhohmFiJ+CYVCdOnShREjRtC1a1duvfVWjh07RiAQYNKkSQSDQRYsWMDIkSMrn1gXCASYMmUKwWCQuLg48vLygPLnXo8aNYq4uDji4+NZtGgRUP7c7JSUFILBIEOHDq18mt2vfvUrunXrRnx8fOXzKxYsWED37t1JSEigd+/ePuwRqc00sxDx0c6dO3n55ZdJTU1l9OjRPPfccwC0bNmSnJwcAJYuXVrlM61atSInJ4fnnnuOGTNm8Pvf/56HH36Y5s2bs23bNgAKCws5ePAgjzzyCCtXriQ6OprHH3+cmTNnctddd7FkyRLy8vIwMw4dOgTAtGnTWLZsGZdccknleyJf08xCxEft2rUjNTUVgDvuuIP169cDMGzYsDN+5pZbbgEgKSmJUCgEwMqVK7nrrrsq21xwwQV88MEH7Nixg9TUVHr06MGrr77KP/7xD5o3b05UVBQ/+clPWLx4Meeddx4AqampjBw5kpdeeonS0tJwDFfqMM0sRHxkZqddjo6OPuNnIiMjAYiIiKCkpOSM7Zxz9O/fn3nz5p2ybtOmTaxatYqFCxfy7LPPsnr1al544QU+/PBD3n33XZKSksjOzqZly5ZnMyyph85pZmFmQ81su5mVmVnyN9bdb2b5ZrbTzAacW5ki9dOePXvYuHEjAHPnzqVXr15n1U///v2ZNWtW5XJhYSFXXXUVGzZsID8/H4CjR4+ya9cuioqKOHz4MDfccANPPvkkW7duBeB//ud/uPLKK5k2bRoxMTH885//PMfRSX1yroehcoFbgLUnv2lm3YDbgVhgIPCcmUWc47ZE6p3OnTsza9YsunbtSmFhIePHjz+rfh588EEKCwsrT1CvWbOGmJgYMjIyGD58OPHx8aSkpJCXl8eRI0dIT08nPj6eXr16MXPmTAAmTpxIXFwc3bt35+qrryYhIaE6hyp1nDnnzr0Ts/eBe51zWRXL9wM4535TsbwMmOqc2/ht/SQnJ7usrKxzrkekLgiFQqSnp5Obm+t3KVLHmVm2cy7Zu+XZC9cJ7kuAk+eweyveExGROsjzBLeZrQQuOs2qB5xzfz7XAsxsHDAO4LLLLjvX7kTqjEAgoFmF1BmeYeGcu+4s+t0HtDtp+dKK907X/2xgNpQfhjqLbYmISJiF6zDUW8DtZhZpZh2AjsCmMG1LRETC7FwvnR1sZnuBFODdihPZOOe2A38CdgBLgbucc/qWj4hIHXVOX8pzzi0Blpxh3aPAo+fSv4iI1A663YeIiHhSWIiIiCeFhYiIeFJYiIiIJ4WFiIh4UliIiIgnhYWIiHhSWIiIiCeFhYiIeFJYiIiIJ4WFiIh4UliIiIgnhYWISDWaPn06zzzzDAD33HMP/fr1A2D16tWMGDGCefPmVT7rfNKkSZWfa9asGRMnTiQ2NpbrrruOTZs2cc0113D55Zfz1ltvAeWP4k1LSyMYDBIMBvnb3/729cfPN7P3zWyhmeWZ2R/NzKpzXAoLEZFqlJaWxrp16wDIysqiqKiI4uJi1q1bR6dOnZg0aRKrV69my5YtZGZm8uabbwJw9OhR+vXrx/bt2zn//PN58MEHWbFiBUuWLGHy5MkAtG7dmhUrVpCTk8P8+fO5++67T950IjAB6AZcDqRW57gUFiIi1SgpKYns7Gy++OILIiMjSUlJISsri3Xr1tGiRQuuueYaYmJiaNy4MSNGjGDt2rUANG3alIEDBwIQFxdHnz59aNKkCXFxcYRCIQCKi4sZO3YscXFxDB06lB07dpy86U3Oub3OuTJgCxCoznGd0/MsRESkqiZNmtChQwcyMjK4+uqriY+PZ82aNeTn5xMIBMjOzj7j574+ctSoUSMiIyMrX5eUlADw5JNP0qZNG7Zu3UpZWRlRUVEnd3HipNelVPPfd80sRESqWVpaGjNmzKB3796kpaXxwgsvkJiYyBVXXMFf//pXDh48SGlpKfPmzaNPnz7fud/Dhw9z8cUX06hRI1577TVKS2vuAaQKCxGRapaWlsb+/ftJSUmhTZs2REVFkZaWxsUXX8xjjz1G3759SUhIICkpiUGDBn3nfn/605/y6quvkpCQQF5eHtHR0WEcRVXmnKuxjXkxswLgH2HouhVwMAz91lXaH1Vpf5xK+6Sq2r4/2jvnYsK5gVoVFuFiZlnOuWS/66gttD+q0v44lfZJVdofOgwlIiLfgcJCREQ8NZSwmO13AbWM9kdV2h+n0j6pqsHvjwZxzkJERM5NQ5lZiIjIOVBYiIiIpwYVFmb284o7Mm43syf8rqc2MLNfmpkzs1Z+1+InM5te8bvxdzNbYmYt/K7JD2Y20Mx2mlm+mf3K73r8ZmbtzGyNme2o+LvxC79r8kuDCQsz6wsMAhKcc7HADJ9L8p2ZtQOuB/b4XUstsALo7pyLB3YB9/tcT40zswhgFvADyu9cOtzMuvlble9KgF8657oBVwF3NdR90mDCAhgPPOacOwHgnPvc53pqgyeB+4AGf5WDc265c66kYvED4FI/6/HJFUC+c+5j59xXwBuU/werwXLO7XfO5VS8PgJ8BFzib1X+aEhh0QlIM7MPzeyvZtbT74L8ZGaDgH3Oua1+11ILjQb+4ncRPrgE+OdJy3tpoH8YT8fMApQ/M+JDfyvxR726RbmZrQQuOs2qBygf64WUTyV7An8ys8tdPb522GN//Dflh6AajG/bH865P1e0eYDyQw9/rMnapHYzs2bAImCCc+4Lv+vxQ70KC+fcdWdaZ2bjgcUV4bDJzMoovzlYQU3VV9POtD/MLA7oAGytuH/+pUCOmV3hnDtQgyXWqG/7/QAws5FAOnBtff5PxLfYB7Q7afnSivcaNDNrQnlQ/NE5t9jvevzSkA5DvQn0BTCzTkBTavddJMPGObfNOW3PFVUAAAC0SURBVNfaORdwzgUoP9wQrM9B4cXMBlJ+/uZm59wxv+vxSSbQ0cw6mFlT4HbgLZ9r8lXFc6xfBj5yzs30ux4/NaSwmANcbma5lJ+4+3ED/d+jnN6zwPnACjPbYmYv+F1QTas4wf8zYBnlJ3L/5Jzb7m9VvksFfgT0q/i92GJmN/hdlB90uw8REfHUkGYWIiJylhQWIiLiSWEhIiKeFBYiIuJJYSEiIp4UFiIi4klhISIinv4fV563gzeoNDkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cyLiVub8yFv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ0FCgOo8yMs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTmbOkw98yS7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajbtF74e8yaZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iR1VSxG8yrS",
        "outputId": "43b529aa-8649-47f4-907b-fce3a13f6908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "%matplotlib notebook\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "# Fixing random state for reproducibility\n",
        "np.random.seed(19680801)\n",
        "\n",
        "N = 50\n",
        "x = np.random.rand(N)\n",
        "y = np.random.rand(N)\n",
        "colors = np.random.rand(N)\n",
        "area = (30 * np.random.rand(N))**2  # 0 to 15 point radii\n",
        "\n",
        "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYb1ael9usSg"
      },
      "source": [
        "\n",
        "\n",
        "# # making placeholders for X_train and Y_train\n",
        "# x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
        "# y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
        "\n",
        "# # word embedding will be 2 dimension for 2d visualization\n",
        "# EMBEDDING_DIM = 2 \n",
        "\n",
        "# # hidden layer: which represents word vector eventually\n",
        "# W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
        "# b1 = tf.Variable(tf.random_normal([1])) #bias\n",
        "# hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
        "\n",
        "# # output layer\n",
        "# W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
        "# b2 = tf.Variable(tf.random_normal([1]))\n",
        "# prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
        "\n",
        "# # loss function: cross entropy\n",
        "# loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
        "\n",
        "# # training operation\n",
        "# train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvm9D1zXusSj"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoEvFBjkusSj"
      },
      "source": [
        "# sess = tf.Session()\n",
        "# init = tf.global_variables_initializer()\n",
        "# sess.run(init) \n",
        "\n",
        "# iteration = 20000\n",
        "# for i in range(iteration):\n",
        "#     # input is X_train which is one hot encoded word\n",
        "#     # label is Y_train which is one hot encoded neighbor word\n",
        "#     sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
        "#     if i % 3000 == 0:\n",
        "#         print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TegWDoAusSn"
      },
      "source": [
        "# # Now the hidden layer (W1 + b1) is actually the word look up table\n",
        "# vectors = sess.run(W1 + b1)\n",
        "# print(vectors)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj6_nlKNusSs"
      },
      "source": [
        "# word vector in table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3nPt6lFusSs",
        "outputId": "bf8131ca-7c5f-48d9-c68e-da5ee243af12"
      },
      "source": [
        "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
        "w2v_df['word'] = words\n",
        "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
        "w2v_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>strong</td>\n",
              "      <td>-5.074393</td>\n",
              "      <td>3.714381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prince</td>\n",
              "      <td>-6.660943</td>\n",
              "      <td>-0.225515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>boy</td>\n",
              "      <td>-1.573136</td>\n",
              "      <td>0.538650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>princess</td>\n",
              "      <td>-1.737352</td>\n",
              "      <td>-4.974859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>king</td>\n",
              "      <td>-0.665455</td>\n",
              "      <td>0.615576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man</td>\n",
              "      <td>-0.368308</td>\n",
              "      <td>0.569896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>young</td>\n",
              "      <td>-0.361708</td>\n",
              "      <td>-0.130939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>wise</td>\n",
              "      <td>-2.511614</td>\n",
              "      <td>-5.351053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>girl</td>\n",
              "      <td>-2.337072</td>\n",
              "      <td>-3.970424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>pretty</td>\n",
              "      <td>-3.097544</td>\n",
              "      <td>-3.623812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>queen</td>\n",
              "      <td>-0.554055</td>\n",
              "      <td>-1.481090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>woman</td>\n",
              "      <td>-0.020509</td>\n",
              "      <td>-1.324963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word        x1        x2\n",
              "0     strong -5.074393  3.714381\n",
              "1     prince -6.660943 -0.225515\n",
              "2        boy -1.573136  0.538650\n",
              "3   princess -1.737352 -4.974859\n",
              "4       king -0.665455  0.615576\n",
              "5        man -0.368308  0.569896\n",
              "6      young -0.361708 -0.130939\n",
              "7       wise -2.511614 -5.351053\n",
              "8       girl -2.337072 -3.970424\n",
              "9     pretty -3.097544 -3.623812\n",
              "10     queen -0.554055 -1.481090\n",
              "11     woman -0.020509 -1.324963"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs9x8wR1usSy"
      },
      "source": [
        "# word vector in 2d chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXsTwgeEusSz",
        "outputId": "707b74fa-1eca-4747-cc8f-f903e0d79783"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
        "    ax.annotate(word, (x1,x2 ))\n",
        "    \n",
        "PADDING = 1.0\n",
        "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
        "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
        "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
        "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
        " \n",
        "plt.xlim(x_axis_min,x_axis_max)\n",
        "plt.ylim(y_axis_min,y_axis_max)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}